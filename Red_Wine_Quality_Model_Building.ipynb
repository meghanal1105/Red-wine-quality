{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH4l_TqQ7Jhy",
        "outputId": "93428847-f9c7-4d96-a435-4babc9c9cfa4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from scipy.stats import chi2_contingency\n",
        "import statsmodels.formula.api as smf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 38,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "hprc0UYa7dkd",
        "outputId": "55b1df57-351b-48e4-ae8a-57329fe28662"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ef1ef276-a6bb-4407-9f9b-862d31c655cb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ef1ef276-a6bb-4407-9f9b-862d31c655cb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01omqdVv7gXr"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv(\"EDA_RedWine.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y8BQEui9K24",
        "outputId": "95ea6d30-848b-4a0b-acef-59599632c829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Unnamed: 0            1599 non-null   int64  \n",
            " 1   fixed_acidity         1599 non-null   float64\n",
            " 2   volatile_acidity      1599 non-null   float64\n",
            " 3   citric_acid           1599 non-null   float64\n",
            " 4   residual_sugar        1599 non-null   float64\n",
            " 5   chlorides             1599 non-null   float64\n",
            " 6   free_sulfur_dioxide   1599 non-null   float64\n",
            " 7   total_sulfur_dioxide  1599 non-null   float64\n",
            " 8   density               1599 non-null   float64\n",
            " 9   pH                    1599 non-null   float64\n",
            " 10  sulphates             1599 non-null   float64\n",
            " 11  alcohol               1599 non-null   float64\n",
            " 12  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 162.5 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vjAGntS9qRT"
      },
      "outputs": [],
      "source": [
        "df= df.drop(['Unnamed: 0'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-bLd07O9yLm",
        "outputId": "5d438032-35fa-43dd-e6de-abcd7ba4cc6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed_acidity         1599 non-null   float64\n",
            " 1   volatile_acidity      1599 non-null   float64\n",
            " 2   citric_acid           1599 non-null   float64\n",
            " 3   residual_sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free_sulfur_dioxide   1599 non-null   float64\n",
            " 6   total_sulfur_dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy6xxRzM9NA9",
        "outputId": "69b364f8-e2fb-429f-b6bc-2123f9919494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fixed_acidity           0\n",
              "volatile_acidity        0\n",
              "citric_acid             0\n",
              "residual_sugar          0\n",
              "chlorides               0\n",
              "free_sulfur_dioxide     0\n",
              "total_sulfur_dioxide    0\n",
              "density                 0\n",
              "pH                      0\n",
              "sulphates               0\n",
              "alcohol                 0\n",
              "quality                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "2cCS5veC9PZe",
        "outputId": "b75501d1-4945-445d-dfa6-a532c772e787"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed_acidity</th>\n",
              "      <th>volatile_acidity</th>\n",
              "      <th>citric_acid</th>\n",
              "      <th>residual_sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free_sulfur_dioxide</th>\n",
              "      <th>total_sulfur_dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.290901</td>\n",
              "      <td>0.526429</td>\n",
              "      <td>0.270922</td>\n",
              "      <td>2.322358</td>\n",
              "      <td>0.081194</td>\n",
              "      <td>15.689181</td>\n",
              "      <td>45.714822</td>\n",
              "      <td>0.996742</td>\n",
              "      <td>3.310353</td>\n",
              "      <td>0.649831</td>\n",
              "      <td>10.419627</td>\n",
              "      <td>3.636023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.655860</td>\n",
              "      <td>0.174045</td>\n",
              "      <td>0.194614</td>\n",
              "      <td>0.609493</td>\n",
              "      <td>0.017822</td>\n",
              "      <td>9.837494</td>\n",
              "      <td>30.374029</td>\n",
              "      <td>0.001806</td>\n",
              "      <td>0.149851</td>\n",
              "      <td>0.137086</td>\n",
              "      <td>1.054808</td>\n",
              "      <td>0.807569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.600000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.992247</td>\n",
              "      <td>2.925000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.995600</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.996750</td>\n",
              "      <td>3.310000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.200000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.997835</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12.350000</td>\n",
              "      <td>1.015000</td>\n",
              "      <td>0.915000</td>\n",
              "      <td>3.650000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>1.001187</td>\n",
              "      <td>3.685000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fixed_acidity  volatile_acidity  ...      alcohol      quality\n",
              "count    1599.000000       1599.000000  ...  1599.000000  1599.000000\n",
              "mean        8.290901          0.526429  ...    10.419627     3.636023\n",
              "std         1.655860          0.174045  ...     1.054808     0.807569\n",
              "min         4.600000          0.120000  ...     8.400000     1.000000\n",
              "25%         7.100000          0.390000  ...     9.500000     3.000000\n",
              "50%         7.900000          0.520000  ...    10.200000     4.000000\n",
              "75%         9.200000          0.640000  ...    11.100000     4.000000\n",
              "max        12.350000          1.015000  ...    13.500000     6.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbgRs8H-9SjT",
        "outputId": "5f4bf59c-9887-428b-9841-82c084913edb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1599, 12)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDW_jaBV9TtG"
      },
      "outputs": [],
      "source": [
        "X = df.loc[:, df.columns != 'quality']\n",
        "y = df.loc[:, df.columns == 'quality']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTXCFYxX-1nv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deiRQkTM-7LW"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state= 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBYa9BIR--kP"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFEzY3y-_fyj"
      },
      "outputs": [],
      "source": [
        "\"\"\"#Logistic Regression\n",
        "\n",
        "#### Log_r\n",
        "\"\"\"\n",
        "\n",
        "Log_r= LogisticRegression(max_iter= 100000000000000000000000000000000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeEGEd_X_2C0",
        "outputId": "e0b1b492-bb34-4656-f464-9876c9b70437"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "Log_r = Log_r.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PH9FsUl_5PB",
        "outputId": "8c3bfd5d-f94d-4ab2-ca17-e7a40922b328"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 4])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train = Log_r.predict(X_train)\n",
        "y_pred_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcBlcHm-AFJp",
        "outputId": "4f897787-8b43-4207-fb92-d43d15762b8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 3, 3, 5, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 5, 4, 4, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3,\n",
              "       3, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 5, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 5, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4,\n",
              "       3, 4, 4, 3, 4, 5, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3,\n",
              "       3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3,\n",
              "       4, 4, 4, 3, 3, 3, 5, 5, 4, 4, 3, 3, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4,\n",
              "       3, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4,\n",
              "       4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 5, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test = Log_r.predict(X_test)\n",
        "y_pred_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rChn3mq3AILJ"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4SQQ-IdALYF",
        "outputId": "f1aa116b-c362-48ba-a656-65f29a29c81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.610366398570152\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_train,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFP0S3eCAU9O",
        "outputId": "130d22dd-a71e-410b-8ff7-ca70eed19d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5541666666666667\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFEHuSj7AXgH"
      },
      "outputs": [],
      "source": [
        "\"\"\"#### Log_r1\"\"\"\n",
        "\n",
        "#Multiclass = ovr\n",
        "\n",
        "Log_r1 = LogisticRegression(multi_class='ovr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFrP7uKgAoaq",
        "outputId": "bf3f8c23-4796-4df1-851a-527c17f75e48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "Log_r1 = Log_r1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxb5KJjkArxk",
        "outputId": "e891a592-78de-4b9a-a94b-0891021c5a08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 4])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train1 = Log_r1.predict(X_train)\n",
        "y_pred_train1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUJHIKw3Ayd0",
        "outputId": "5414f878-6ad2-4ef6-c6a3-9c1a5763b859"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       3, 4, 3, 4, 3, 3, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3,\n",
              "       3, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3,\n",
              "       4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4,\n",
              "       3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test1 = Log_r1.predict(X_test)\n",
        "y_pred_test1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3W03kb8A1X4",
        "outputId": "f5e12be9-0460-42d1-bd4d-cba9e65cdb76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5960679177837355\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_train1,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLPHjVTvA--_",
        "outputId": "b27e8880-a7dc-4cf6-e0b6-09efd83e56c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5416666666666666\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_test1,y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JduAea6MBCZM"
      },
      "outputs": [],
      "source": [
        "\"\"\"#### Log_r2\"\"\"\n",
        "\n",
        "#________multiclass= multinomial, solver = newton_cg\n",
        "\n",
        "Log_r2 = LogisticRegression(multi_class='multinomial',solver='newton-cg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asYq3vU3BI2U",
        "outputId": "ec772b83-760b-47d1-d62a-d055b5832fb1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "Log_r2 = Log_r2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2xClLNZBNqt",
        "outputId": "4b38fcb2-9d58-418f-e8fa-1c38b14b06dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 4])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train2 = Log_r2.predict(X_train)\n",
        "y_pred_train2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w384tPToBRKn",
        "outputId": "58a90aad-c77f-4a24-8884-2fa1f25936f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 3, 3, 5, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 5, 4, 4, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3,\n",
              "       3, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 5, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 5, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4,\n",
              "       3, 4, 4, 3, 4, 5, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3,\n",
              "       3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3,\n",
              "       4, 4, 4, 3, 3, 3, 5, 5, 4, 4, 3, 3, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4,\n",
              "       3, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4,\n",
              "       4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 5, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test2 = Log_r2.predict(X_test)\n",
        "y_pred_test2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTwR1vs7BWHL",
        "outputId": "366f264c-5d2b-4c42-a36f-bfeab14d4424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.610366398570152\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_train2,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEQGq_NHBc50",
        "outputId": "dc441e2d-0110-42a6-d1d6-c8a9a14389b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5541666666666667\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_test2,y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMj-Lvq5BgIw"
      },
      "outputs": [],
      "source": [
        "\"\"\"#### Log_r3\"\"\"\n",
        "\n",
        "#________multiclass= multinomial, solver = lbfgs\n",
        "\n",
        "Log_r3 = LogisticRegression(multi_class='multinomial',solver='lbfgs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRS6stJ9Brq7",
        "outputId": "b8ac35c5-0f5a-448b-889f-9fff27838ca9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "Log_r3 = Log_r3.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2w3jfduBvQW",
        "outputId": "46a5c715-145d-4fa6-c5e5-2c1f7e0996e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 3])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train3 = Log_r3.predict(X_train)\n",
        "y_pred_train3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRIZwJfbBzmz",
        "outputId": "90597c28-9735-4ceb-b3be-31cdc001cfec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3,\n",
              "       3, 3, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, 4, 3, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 5, 3, 3, 4, 3, 3, 3, 4,\n",
              "       3, 4, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3,\n",
              "       4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 3, 5, 4,\n",
              "       3, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 3, 3,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 5,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 3, 3])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test3 = Log_r3.predict(X_test)\n",
        "y_pred_test3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXLKC9a-B1_v",
        "outputId": "67e7a595-f0d4-4dac-f208-e530e66acdf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6014298480786416\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_train3,y_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_UmiuWsB74l",
        "outputId": "46722769-03e8-4abe-85dc-98cf2d9c2a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5375\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_test3,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP0L6b1yB_F9"
      },
      "outputs": [],
      "source": [
        "\"\"\"#### Log_r4\"\"\"\n",
        "\n",
        "#________multiclass= multinomial, solver = sag\n",
        "\n",
        "Log_r4 = LogisticRegression(multi_class='multinomial',solver='sag')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hswwis1PCfpj",
        "outputId": "8eb4f7bf-1a86-4c4b-d664-7c64bd3b2d75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "Log_r4 = Log_r4.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9xu2uC8CjUs",
        "outputId": "1fb01cae-9d76-4cc6-8b6a-fc5145ade71c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 3])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train4 = Log_r4.predict(X_train)\n",
        "y_pred_train4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy6uKE8jCneI",
        "outputId": "74bfe503-beab-4884-ac33-722f76a0fd07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 4, 3,\n",
              "       3, 3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       3, 3, 4, 3, 3, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 4,\n",
              "       3, 4, 3, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3,\n",
              "       4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 3, 4, 3, 4, 4, 3, 3,\n",
              "       4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4,\n",
              "       3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 4, 4, 3, 3, 4, 4, 4, 3, 3,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test4 = Log_r4.predict(X_test)\n",
        "y_pred_test4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db7t7EQkCr41",
        "outputId": "b939d7c1-f6a8-42cf-ecc0-26f845745f09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5978552278820375\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_train4,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfZT2-dqCvw2",
        "outputId": "03629bf4-04ff-441d-df76-6f560df55153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.50625\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_test4,y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEbJ2Hb3Cy4p"
      },
      "outputs": [],
      "source": [
        "\"\"\"#### Log_5\"\"\"\n",
        "\n",
        "#________multiclass= multinomial, solver = saga\n",
        "\n",
        "Log_r5 = LogisticRegression(multi_class='multinomial',solver='saga')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efjcn_dnC54l",
        "outputId": "8f6e1571-53c3-4e34-e234-b3f037636450"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "Log_r5 = Log_r5.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q7t3oYGC8_Z",
        "outputId": "bca3e254-8b57-4d20-b119-c31ed6562202"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 4, 4, ..., 4, 3, 3])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train5 = Log_r5.predict(X_train)\n",
        "y_pred_train5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWaB4nwzDAKJ",
        "outputId": "f5f02f90-72c7-4d0a-8121-9a6a513f9997"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 4, 4, 4, 3, 4, 3, 4, 4,\n",
              "       3, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3,\n",
              "       3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 4, 4, 3, 3, 4, 4, 4, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4,\n",
              "       3, 4, 3, 3, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3,\n",
              "       4, 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 4, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3,\n",
              "       4, 3, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 3, 4, 3, 4, 4, 3, 3,\n",
              "       4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4,\n",
              "       3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,\n",
              "       4, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 4, 4, 4, 3, 3,\n",
              "       4, 4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test5 = Log_r5.predict(X_test)\n",
        "y_pred_test5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtVQk2etDKP8",
        "outputId": "c666e592-523e-4c4a-f2d7-3e8ddbc48efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5630026809651475\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_train5,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDMaYhrmDOdF",
        "outputId": "79316ab0-5f67-4047-fda5-f9c56b128d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5020833333333333\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_test5,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05hcXUbEDfxu"
      },
      "outputs": [],
      "source": [
        "#From the above experiment, We got the best accuracy from ----\n",
        "# -----> Log_r2, i.e \n",
        "# (multi_class='multinomial',solver='newton-cg')\n",
        "#So let's find best parameters using Grid Search & CV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzJEzvMaFpXJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"#### Grid Search (Log_r)\"\"\"\n",
        "#_________gridsearch (Log_R) \n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSXqbzBVFvQh"
      },
      "outputs": [],
      "source": [
        "penalty = ['l1','l2']\n",
        "max_iter=[80, 100, 140]\n",
        "C = np.linspace(0.1, 1.0, num=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "npUyZyQMF_27",
        "outputId": "2dc4a711-e6ac-4f66-981a-941f3540347d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed_acidity</th>\n",
              "      <th>volatile_acidity</th>\n",
              "      <th>citric_acid</th>\n",
              "      <th>residual_sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free_sulfur_dioxide</th>\n",
              "      <th>total_sulfur_dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>9.8</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.39</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.083</td>\n",
              "      <td>21.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.99890</td>\n",
              "      <td>3.37</td>\n",
              "      <td>0.71</td>\n",
              "      <td>11.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.605</td>\n",
              "      <td>0.02</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.096</td>\n",
              "      <td>10.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.99500</td>\n",
              "      <td>3.46</td>\n",
              "      <td>0.53</td>\n",
              "      <td>11.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>9.1</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.34</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.064</td>\n",
              "      <td>12.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.99516</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.84</td>\n",
              "      <td>11.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>7.7</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.074</td>\n",
              "      <td>9.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.99615</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.48</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.820</td>\n",
              "      <td>0.05</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.081</td>\n",
              "      <td>26.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.99814</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.53</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed_acidity  volatile_acidity  citric_acid  ...    pH  sulphates  alcohol\n",
              "318             9.8             0.660         0.39  ...  3.37       0.71     11.5\n",
              "1364            7.2             0.605         0.02  ...  3.46       0.53     11.8\n",
              "1007            9.1             0.300         0.34  ...  3.26       0.84     11.7\n",
              "248             7.7             0.530         0.06  ...  3.35       0.48      9.8\n",
              "782             9.0             0.820         0.05  ...  3.36       0.53     10.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78i6PpnOGDHs"
      },
      "outputs": [],
      "source": [
        "param_grid = dict(max_iter=max_iter, C=C, penalty=penalty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efO1nXk6W9z6"
      },
      "outputs": [],
      "source": [
        "Log_r_gs = LogisticRegression(multi_class='multinomial',solver='newton-cg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_Hzphu6XTRP"
      },
      "outputs": [],
      "source": [
        "g_search = GridSearchCV(estimator = Log_r_gs, param_grid = param_grid, cv = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKwzk-piXVyS",
        "outputId": "9e785d69-b8b7-47c2-ec29-27a937772a6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "75 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.5915639         nan 0.5915639         nan 0.5915639\n",
            "        nan 0.60138933        nan 0.60138933        nan 0.60138933\n",
            "        nan 0.60407191        nan 0.60407191        nan 0.60407191\n",
            "        nan 0.60675048        nan 0.60675048        nan 0.60675048\n",
            "        nan 0.60316304        nan 0.60316304        nan 0.60316304]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "g_mod = g_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-9cc3ZaXn3O",
        "outputId": "8c77f87f-7a03-4535-c744-49f91d03ccfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 3, 3, 5, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 5, 4, 4, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3,\n",
              "       3, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 5, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 5, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4,\n",
              "       3, 4, 4, 3, 4, 5, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3,\n",
              "       3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3,\n",
              "       4, 4, 4, 3, 3, 3, 5, 5, 4, 4, 3, 3, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4,\n",
              "       3, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4,\n",
              "       4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 5, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test_gs = g_mod.predict(X_test)\n",
        "y_pred_test_gs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw-vSqayYqox",
        "outputId": "6772fc6c-26e4-4d95-d21b-3bcf76eecef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best accuracy : 0.606750 using {'C': 0.775, 'max_iter': 80, 'penalty': 'l2'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Best accuracy : %f using %s\" % (g_mod.best_score_, g_mod.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA3NwefVYvA4"
      },
      "outputs": [],
      "source": [
        "Log_r_best = LogisticRegression(multi_class='multinomial',solver='newton-cg', \n",
        "                                C= 0.775, max_iter= 80, penalty= 'l2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96PG-XNlZZms",
        "outputId": "3610818b-6074-483f-84dd-9fb43b4943d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "Log_r_best = Log_r_best.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL1PovFoZcwJ",
        "outputId": "1efa1e63-fa5a-444e-f323-9938a6fa4c37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 4])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train_best = Log_r_best.predict(X_train)\n",
        "y_pred_train_best\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgeuCkrRZfHs",
        "outputId": "d3c15200-d057-424d-8c94-b778e95f5113"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 3, 3, 5, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 5, 4, 4, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3,\n",
              "       3, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 5, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
              "       4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 5, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4,\n",
              "       3, 4, 4, 3, 4, 5, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3,\n",
              "       3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3,\n",
              "       4, 4, 4, 3, 3, 3, 5, 5, 4, 4, 3, 3, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4,\n",
              "       3, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       4, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4,\n",
              "       4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 5, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test_best = Log_r_best.predict(X_test)\n",
        "y_pred_test_best\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKWZnukUZh7y",
        "outputId": "dc273a68-ac3f-4627-a4f3-5bf3aaddc768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.612153708668454\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_train_best,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4ecUwLfaUiM",
        "outputId": "867aaa87-e881-4bd6-db0f-402f057e6595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5541666666666667\n"
          ]
        }
      ],
      "source": [
        "print(metrics.accuracy_score(y_pred_test_best,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O96qwvjhak6y"
      },
      "source": [
        "**# Decision Tree Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrCjFYJraYWL"
      },
      "outputs": [],
      "source": [
        "#Importing algorithm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWUM7jaXat00"
      },
      "outputs": [],
      "source": [
        "dt_clf = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee2ADiNtbmem",
        "outputId": "54fd25b5-d924-4210-9e85-02cd662b0b1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Fit this classifier model on train data set\n",
        "dt_clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwy2Y2MQb11-"
      },
      "outputs": [],
      "source": [
        "y_pred_train_dt = dt_clf.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9Xf04EVdOuv"
      },
      "outputs": [],
      "source": [
        "y_pred_test_dt = dt_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iD8HnAXodRf8",
        "outputId": "0d36e46d-2eac-4a41-b835-e7958c73ab2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(148.51032490632974, 212.49818181818182, 'X[10] <= 10.25\\ngini = 0.636\\nsamples = 1119\\nvalue = [6, 35, 502, 430, 132, 14]'),\n",
              " Text(43.0692626953125, 202.61454545454546, 'X[1] <= 0.317\\ngini = 0.504\\nsamples = 603\\nvalue = [4, 18, 388, 171, 20, 2]'),\n",
              " Text(10.818367346938777, 192.73090909090908, 'X[6] <= 79.0\\ngini = 0.55\\nsamples = 42\\nvalue = [0, 0, 9, 26, 6, 1]'),\n",
              " Text(9.679591836734694, 182.84727272727272, 'X[4] <= 0.104\\ngini = 0.489\\nsamples = 38\\nvalue = [0, 0, 5, 26, 6, 1]'),\n",
              " Text(6.832653061224491, 172.96363636363637, 'X[0] <= 11.7\\ngini = 0.42\\nsamples = 35\\nvalue = [0, 0, 3, 26, 5, 1]'),\n",
              " Text(4.555102040816327, 163.07999999999998, 'X[7] <= 0.996\\ngini = 0.261\\nsamples = 27\\nvalue = [0, 0, 3, 23, 1, 0]'),\n",
              " Text(3.4163265306122454, 153.19636363636363, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(5.6938775510204085, 153.19636363636363, 'X[7] <= 1.0\\ngini = 0.204\\nsamples = 26\\nvalue = [0, 0, 3, 23, 0, 0]'),\n",
              " Text(4.555102040816327, 143.31272727272727, 'X[6] <= 47.5\\ngini = 0.147\\nsamples = 25\\nvalue = [0, 0, 2, 23, 0, 0]'),\n",
              " Text(2.2775510204081635, 133.42909090909092, 'X[4] <= 0.089\\ngini = 0.087\\nsamples = 22\\nvalue = [0, 0, 1, 21, 0, 0]'),\n",
              " Text(1.1387755102040817, 123.54545454545455, 'gini = 0.0\\nsamples = 18\\nvalue = [0, 0, 0, 18, 0, 0]'),\n",
              " Text(3.4163265306122454, 123.54545454545455, 'X[5] <= 5.0\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 1, 3, 0, 0]'),\n",
              " Text(2.2775510204081635, 113.66181818181819, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(4.555102040816327, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(6.832653061224491, 133.42909090909092, 'X[10] <= 9.85\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 1, 2, 0, 0]'),\n",
              " Text(5.6938775510204085, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(7.971428571428572, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(6.832653061224491, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(9.110204081632654, 163.07999999999998, 'X[1] <= 0.265\\ngini = 0.594\\nsamples = 8\\nvalue = [0, 0, 0, 3, 4, 1]'),\n",
              " Text(7.971428571428572, 153.19636363636363, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0]'),\n",
              " Text(10.248979591836736, 153.19636363636363, 'X[9] <= 0.81\\ngini = 0.56\\nsamples = 5\\nvalue = [0, 0, 0, 3, 1, 1]'),\n",
              " Text(9.110204081632654, 143.31272727272727, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(11.387755102040817, 143.31272727272727, 'X[7] <= 0.999\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 0, 0, 1, 1]'),\n",
              " Text(10.248979591836736, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(12.5265306122449, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(12.5265306122449, 172.96363636363637, 'X[9] <= 0.815\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 0, 1, 0]'),\n",
              " Text(11.387755102040817, 163.07999999999998, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(13.665306122448982, 163.07999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(11.957142857142859, 182.84727272727272, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0]'),\n",
              " Text(75.32015804368623, 192.73090909090908, 'X[9] <= 0.535\\ngini = 0.475\\nsamples = 561\\nvalue = [4, 18, 379, 145, 14, 1]'),\n",
              " Text(30.284311224489798, 182.84727272727272, 'X[10] <= 9.55\\ngini = 0.325\\nsamples = 143\\nvalue = [1, 9, 116, 16, 1, 0]'),\n",
              " Text(21.636734693877553, 172.96363636363637, 'X[10] <= 9.15\\ngini = 0.167\\nsamples = 78\\nvalue = [0, 4, 71, 3, 0, 0]'),\n",
              " Text(17.081632653061227, 163.07999999999998, 'X[9] <= 0.485\\ngini = 0.593\\nsamples = 9\\nvalue = [0, 2, 5, 2, 0, 0]'),\n",
              " Text(14.804081632653062, 153.19636363636363, 'X[9] <= 0.45\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 0, 2, 0, 0]'),\n",
              " Text(13.665306122448982, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(15.942857142857145, 143.31272727272727, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(19.35918367346939, 153.19636363636363, 'X[3] <= 3.125\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 1, 5, 0, 0, 0]'),\n",
              " Text(18.220408163265308, 143.31272727272727, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(20.497959183673473, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(26.19183673469388, 163.07999999999998, 'X[0] <= 6.55\\ngini = 0.084\\nsamples = 69\\nvalue = [0, 2, 66, 1, 0, 0]'),\n",
              " Text(23.914285714285718, 153.19636363636363, 'X[1] <= 0.45\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 0, 4, 1, 0, 0]'),\n",
              " Text(22.775510204081634, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(25.0530612244898, 143.31272727272727, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0]'),\n",
              " Text(28.469387755102044, 153.19636363636363, 'X[10] <= 9.35\\ngini = 0.061\\nsamples = 64\\nvalue = [0, 2, 62, 0, 0, 0]'),\n",
              " Text(27.330612244897964, 143.31272727272727, 'X[7] <= 0.998\\ngini = 0.208\\nsamples = 17\\nvalue = [0, 2, 15, 0, 0, 0]'),\n",
              " Text(26.19183673469388, 133.42909090909092, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12, 0, 0, 0]'),\n",
              " Text(28.469387755102044, 133.42909090909092, 'X[8] <= 3.225\\ngini = 0.48\\nsamples = 5\\nvalue = [0, 2, 3, 0, 0, 0]'),\n",
              " Text(27.330612244897964, 123.54545454545455, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(29.608163265306125, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0, 0, 0, 0]'),\n",
              " Text(29.608163265306125, 143.31272727272727, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 0, 47, 0, 0, 0]'),\n",
              " Text(38.931887755102046, 172.96363636363637, 'X[1] <= 0.465\\ngini = 0.474\\nsamples = 65\\nvalue = [1, 5, 45, 13, 1, 0]'),\n",
              " Text(35.58673469387755, 163.07999999999998, 'X[2] <= 0.245\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 0, 2, 4, 0, 0]'),\n",
              " Text(34.447959183673476, 153.19636363636363, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 4, 0, 0]'),\n",
              " Text(36.72551020408164, 153.19636363636363, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(42.27704081632653, 163.07999999999998, 'X[10] <= 9.85\\ngini = 0.438\\nsamples = 59\\nvalue = [1, 5, 43, 9, 1, 0]'),\n",
              " Text(39.0030612244898, 153.19636363636363, 'X[6] <= 88.5\\ngini = 0.579\\nsamples = 31\\nvalue = [1, 4, 18, 8, 0, 0]'),\n",
              " Text(35.871428571428574, 143.31272727272727, 'X[8] <= 3.265\\ngini = 0.496\\nsamples = 25\\nvalue = [1, 4, 17, 3, 0, 0]'),\n",
              " Text(33.02448979591837, 133.42909090909092, 'X[4] <= 0.08\\ngini = 0.142\\nsamples = 13\\nvalue = [0, 0, 12, 1, 0, 0]'),\n",
              " Text(31.88571428571429, 123.54545454545455, 'X[7] <= 0.996\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1, 0, 0]'),\n",
              " Text(30.746938775510205, 113.66181818181819, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(33.02448979591837, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(34.163265306122454, 123.54545454545455, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9, 0, 0, 0]'),\n",
              " Text(38.71836734693878, 133.42909090909092, 'X[2] <= 0.055\\ngini = 0.681\\nsamples = 12\\nvalue = [1, 4, 5, 2, 0, 0]'),\n",
              " Text(36.440816326530616, 123.54545454545455, 'X[7] <= 0.995\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3, 0, 0, 0, 0]'),\n",
              " Text(35.30204081632653, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0, 0]'),\n",
              " Text(37.5795918367347, 113.66181818181819, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0, 0, 0, 0]'),\n",
              " Text(40.995918367346945, 123.54545454545455, 'X[3] <= 1.75\\ngini = 0.531\\nsamples = 8\\nvalue = [0, 1, 5, 2, 0, 0]'),\n",
              " Text(39.85714285714286, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(42.13469387755102, 113.66181818181819, 'X[8] <= 3.275\\ngini = 0.449\\nsamples = 7\\nvalue = [0, 1, 5, 1, 0, 0]'),\n",
              " Text(40.995918367346945, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(43.27346938775511, 103.77818181818182, 'X[2] <= 0.265\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 1, 5, 0, 0, 0]'),\n",
              " Text(42.13469387755102, 93.89454545454547, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0]'),\n",
              " Text(44.41224489795919, 93.89454545454547, 'X[2] <= 0.275\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1, 0, 0, 0]'),\n",
              " Text(43.27346938775511, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(45.55102040816327, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(42.13469387755102, 143.31272727272727, 'X[0] <= 6.9\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 0, 1, 5, 0, 0]'),\n",
              " Text(40.995918367346945, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(43.27346938775511, 133.42909090909092, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 5, 0, 0]'),\n",
              " Text(45.55102040816327, 153.19636363636363, 'X[1] <= 0.51\\ngini = 0.199\\nsamples = 28\\nvalue = [0, 1, 25, 1, 1, 0]'),\n",
              " Text(44.41224489795919, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(46.68979591836735, 143.31272727272727, 'X[3] <= 1.4\\ngini = 0.14\\nsamples = 27\\nvalue = [0, 0, 25, 1, 1, 0]'),\n",
              " Text(45.55102040816327, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(47.828571428571436, 133.42909090909092, 'X[3] <= 3.475\\ngini = 0.074\\nsamples = 26\\nvalue = [0, 0, 25, 1, 0, 0]'),\n",
              " Text(46.68979591836735, 123.54545454545455, 'gini = 0.0\\nsamples = 23\\nvalue = [0, 0, 23, 0, 0, 0]'),\n",
              " Text(48.96734693877551, 123.54545454545455, 'X[0] <= 7.7\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 1, 0, 0]'),\n",
              " Text(47.828571428571436, 113.66181818181819, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(50.1061224489796, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(120.35600486288267, 182.84727272727272, 'X[0] <= 9.95\\ngini = 0.507\\nsamples = 418\\nvalue = [3, 9, 263, 129, 13, 1]'),\n",
              " Text(102.06609135841838, 172.96363636363637, 'X[6] <= 91.5\\ngini = 0.468\\nsamples = 358\\nvalue = [0, 8, 241, 100, 8, 1]'),\n",
              " Text(83.99136639030613, 163.07999999999998, 'X[1] <= 0.385\\ngini = 0.499\\nsamples = 298\\nvalue = [0, 7, 189, 93, 8, 1]'),\n",
              " Text(65.87104591836736, 153.19636363636363, 'X[6] <= 53.0\\ngini = 0.671\\nsamples = 21\\nvalue = [0, 2, 6, 10, 2, 1]'),\n",
              " Text(61.31594387755103, 143.31272727272727, 'X[10] <= 9.5\\ngini = 0.716\\nsamples = 9\\nvalue = [0, 1, 4, 1, 2, 1]'),\n",
              " Text(59.03839285714286, 133.42909090909092, 'X[4] <= 0.111\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 0, 4, 1, 0, 0]'),\n",
              " Text(57.89961734693878, 123.54545454545455, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0]'),\n",
              " Text(60.177168367346944, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(63.59349489795919, 133.42909090909092, 'X[3] <= 2.05\\ngini = 0.625\\nsamples = 4\\nvalue = [0, 1, 0, 0, 2, 1]'),\n",
              " Text(62.454719387755105, 123.54545454545455, 'X[5] <= 15.5\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 0, 0, 0, 1]'),\n",
              " Text(61.31594387755103, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(63.59349489795919, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(64.73227040816327, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(70.42614795918368, 143.31272727272727, 'X[6] <= 82.5\\ngini = 0.403\\nsamples = 12\\nvalue = [0, 1, 2, 9, 0, 0]'),\n",
              " Text(68.14859693877551, 133.42909090909092, 'X[4] <= 0.069\\ngini = 0.18\\nsamples = 10\\nvalue = [0, 0, 1, 9, 0, 0]'),\n",
              " Text(67.00982142857144, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(69.2873724489796, 123.54545454545455, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 0, 9, 0, 0]'),\n",
              " Text(72.70369897959185, 133.42909090909092, 'X[2] <= 0.51\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1, 0, 0, 0]'),\n",
              " Text(71.56492346938776, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(73.84247448979592, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(102.11168686224491, 153.19636363636363, 'X[4] <= 0.098\\ngini = 0.473\\nsamples = 277\\nvalue = [0, 5, 183, 83, 6, 0]'),\n",
              " Text(91.48459821428573, 143.31272727272727, 'X[4] <= 0.091\\ngini = 0.499\\nsamples = 224\\nvalue = [0, 5, 139, 76, 4, 0]'),\n",
              " Text(82.75695153061226, 133.42909090909092, 'X[0] <= 8.65\\ngini = 0.47\\nsamples = 195\\nvalue = [0, 4, 129, 59, 3, 0]'),\n",
              " Text(76.12002551020409, 123.54545454545455, 'X[7] <= 0.998\\ngini = 0.497\\nsamples = 168\\nvalue = [0, 3, 104, 58, 3, 0]'),\n",
              " Text(66.2625, 113.66181818181819, 'X[2] <= 0.16\\ngini = 0.473\\nsamples = 153\\nvalue = [0, 3, 101, 46, 3, 0]'),\n",
              " Text(58.5045918367347, 103.77818181818182, 'X[1] <= 0.97\\ngini = 0.4\\nsamples = 95\\nvalue = [0, 3, 71, 19, 2, 0]'),\n",
              " Text(53.807142857142864, 93.89454545454547, 'X[4] <= 0.075\\ngini = 0.359\\nsamples = 91\\nvalue = [0, 2, 71, 16, 2, 0]'),\n",
              " Text(47.828571428571436, 84.01090909090911, 'X[6] <= 52.5\\ngini = 0.518\\nsamples = 31\\nvalue = [0, 1, 19, 10, 1, 0]'),\n",
              " Text(46.68979591836735, 74.12727272727273, 'X[0] <= 6.55\\ngini = 0.566\\nsamples = 25\\nvalue = [0, 1, 13, 10, 1, 0]'),\n",
              " Text(45.55102040816327, 64.24363636363637, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(47.828571428571436, 64.24363636363637, 'X[8] <= 3.475\\ngini = 0.585\\nsamples = 20\\nvalue = [0, 1, 8, 10, 1, 0]'),\n",
              " Text(46.68979591836735, 54.360000000000014, 'X[7] <= 0.996\\ngini = 0.561\\nsamples = 17\\nvalue = [0, 1, 5, 10, 1, 0]'),\n",
              " Text(44.41224489795919, 44.47636363636366, 'X[0] <= 6.65\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 0, 4, 1, 0, 0]'),\n",
              " Text(43.27346938775511, 34.592727272727274, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(45.55102040816327, 34.592727272727274, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0]'),\n",
              " Text(48.96734693877551, 44.47636363636366, 'X[10] <= 9.3\\ngini = 0.417\\nsamples = 12\\nvalue = [0, 1, 1, 9, 1, 0]'),\n",
              " Text(47.828571428571436, 34.592727272727274, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(50.1061224489796, 34.592727272727274, 'X[1] <= 0.67\\ngini = 0.314\\nsamples = 11\\nvalue = [0, 0, 1, 9, 1, 0]'),\n",
              " Text(47.828571428571436, 24.709090909090918, 'X[9] <= 0.605\\ngini = 0.198\\nsamples = 9\\nvalue = [0, 0, 0, 8, 1, 0]'),\n",
              " Text(46.68979591836735, 14.825454545454562, 'X[3] <= 2.05\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 0, 1, 1, 0]'),\n",
              " Text(45.55102040816327, 4.941818181818206, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(47.828571428571436, 4.941818181818206, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(48.96734693877551, 14.825454545454562, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 0, 7, 0, 0]'),\n",
              " Text(52.38367346938776, 24.709090909090918, 'X[10] <= 10.0\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1, 0, 0]'),\n",
              " Text(51.24489795918368, 14.825454545454562, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(53.52244897959184, 14.825454545454562, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(48.96734693877551, 54.360000000000014, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(48.96734693877551, 74.12727272727273, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6, 0, 0, 0]'),\n",
              " Text(59.78571428571429, 84.01090909090911, 'X[7] <= 0.995\\ngini = 0.238\\nsamples = 60\\nvalue = [0, 1, 52, 6, 1, 0]'),\n",
              " Text(58.64693877551021, 74.12727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(60.924489795918376, 74.12727272727273, 'X[0] <= 7.65\\ngini = 0.213\\nsamples = 59\\nvalue = [0, 0, 52, 6, 1, 0]'),\n",
              " Text(58.077551020408166, 64.24363636363637, 'X[6] <= 87.0\\ngini = 0.092\\nsamples = 42\\nvalue = [0, 0, 40, 1, 1, 0]'),\n",
              " Text(55.800000000000004, 54.360000000000014, 'X[10] <= 10.15\\ngini = 0.049\\nsamples = 40\\nvalue = [0, 0, 39, 0, 1, 0]'),\n",
              " Text(54.66122448979593, 44.47636363636366, 'gini = 0.0\\nsamples = 35\\nvalue = [0, 0, 35, 0, 0, 0]'),\n",
              " Text(56.93877551020409, 44.47636363636366, 'X[9] <= 0.64\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 0, 4, 0, 1, 0]'),\n",
              " Text(55.800000000000004, 34.592727272727274, 'X[4] <= 0.081\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 0, 1, 0]'),\n",
              " Text(54.66122448979593, 24.709090909090918, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(56.93877551020409, 24.709090909090918, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(58.077551020408166, 34.592727272727274, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(60.355102040816334, 54.360000000000014, 'X[9] <= 0.565\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1, 0, 0]'),\n",
              " Text(59.21632653061225, 44.47636363636366, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(61.49387755102041, 44.47636363636366, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(63.77142857142858, 64.24363636363637, 'X[8] <= 3.3\\ngini = 0.415\\nsamples = 17\\nvalue = [0, 0, 12, 5, 0, 0]'),\n",
              " Text(62.632653061224495, 54.360000000000014, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 0, 10, 0, 0, 0]'),\n",
              " Text(64.91020408163266, 54.360000000000014, 'X[5] <= 13.5\\ngini = 0.408\\nsamples = 7\\nvalue = [0, 0, 2, 5, 0, 0]'),\n",
              " Text(63.77142857142858, 44.47636363636366, 'X[7] <= 0.997\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 1, 0, 0]'),\n",
              " Text(62.632653061224495, 34.592727272727274, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(64.91020408163266, 34.592727272727274, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(66.04897959183674, 44.47636363636366, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 4, 0, 0]'),\n",
              " Text(63.20204081632654, 93.89454545454547, 'X[8] <= 3.335\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 1, 0, 3, 0, 0]'),\n",
              " Text(62.06326530612245, 84.01090909090911, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(64.34081632653061, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(74.02040816326532, 103.77818181818182, 'X[10] <= 9.45\\ngini = 0.515\\nsamples = 58\\nvalue = [0, 0, 30, 27, 1, 0]'),\n",
              " Text(68.89591836734695, 93.89454545454547, 'X[6] <= 37.5\\ngini = 0.397\\nsamples = 22\\nvalue = [0, 0, 16, 6, 0, 0]'),\n",
              " Text(66.61836734693878, 84.01090909090911, 'X[5] <= 5.5\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 0, 2, 4, 0, 0]'),\n",
              " Text(65.4795918367347, 74.12727272727273, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(67.75714285714287, 74.12727272727273, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 4, 0, 0]'),\n",
              " Text(71.1734693877551, 84.01090909090911, 'X[6] <= 85.5\\ngini = 0.219\\nsamples = 16\\nvalue = [0, 0, 14, 2, 0, 0]'),\n",
              " Text(70.03469387755102, 74.12727272727273, 'X[9] <= 0.545\\ngini = 0.124\\nsamples = 15\\nvalue = [0, 0, 14, 1, 0, 0]'),\n",
              " Text(68.89591836734695, 64.24363636363637, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(71.1734693877551, 64.24363636363637, 'gini = 0.0\\nsamples = 14\\nvalue = [0, 0, 14, 0, 0, 0]'),\n",
              " Text(72.31224489795919, 74.12727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(79.14489795918368, 93.89454545454547, 'X[1] <= 0.495\\ngini = 0.508\\nsamples = 36\\nvalue = [0, 0, 14, 21, 1, 0]'),\n",
              " Text(75.72857142857144, 84.01090909090911, 'X[0] <= 6.95\\ngini = 0.524\\nsamples = 15\\nvalue = [0, 0, 9, 5, 1, 0]'),\n",
              " Text(74.58979591836736, 74.12727272727273, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(76.86734693877551, 74.12727272727273, 'X[5] <= 24.0\\ngini = 0.403\\nsamples = 12\\nvalue = [0, 0, 9, 2, 1, 0]'),\n",
              " Text(75.72857142857144, 64.24363636363637, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7, 0, 0, 0]'),\n",
              " Text(78.0061224489796, 64.24363636363637, 'X[7] <= 0.997\\ngini = 0.64\\nsamples = 5\\nvalue = [0, 0, 2, 2, 1, 0]'),\n",
              " Text(76.86734693877551, 54.360000000000014, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(79.14489795918368, 54.360000000000014, 'X[6] <= 56.0\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 0, 1, 0]'),\n",
              " Text(78.0061224489796, 44.47636363636366, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(80.28367346938776, 44.47636363636366, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(82.56122448979593, 84.01090909090911, 'X[0] <= 6.45\\ngini = 0.363\\nsamples = 21\\nvalue = [0, 0, 5, 16, 0, 0]'),\n",
              " Text(81.42244897959185, 74.12727272727273, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(83.7, 74.12727272727273, 'X[3] <= 2.15\\ngini = 0.266\\nsamples = 19\\nvalue = [0, 0, 3, 16, 0, 0]'),\n",
              " Text(82.56122448979593, 64.24363636363637, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 0, 12, 0, 0]'),\n",
              " Text(84.83877551020409, 64.24363636363637, 'X[2] <= 0.215\\ngini = 0.49\\nsamples = 7\\nvalue = [0, 0, 3, 4, 0, 0]'),\n",
              " Text(83.7, 54.360000000000014, 'X[9] <= 0.595\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1, 0, 0]'),\n",
              " Text(82.56122448979593, 44.47636363636366, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(84.83877551020409, 44.47636363636366, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(85.97755102040817, 54.360000000000014, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(85.97755102040817, 113.66181818181819, 'X[6] <= 68.0\\ngini = 0.32\\nsamples = 15\\nvalue = [0, 0, 3, 12, 0, 0]'),\n",
              " Text(84.83877551020409, 103.77818181818182, 'X[8] <= 3.64\\ngini = 0.142\\nsamples = 13\\nvalue = [0, 0, 1, 12, 0, 0]'),\n",
              " Text(83.7, 93.89454545454547, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 0, 11, 0, 0]'),\n",
              " Text(85.97755102040817, 93.89454545454547, 'X[7] <= 0.999\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1, 0, 0]'),\n",
              " Text(84.83877551020409, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(87.11632653061226, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(87.11632653061226, 103.77818181818182, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(89.39387755102042, 123.54545454545455, 'X[5] <= 4.5\\ngini = 0.14\\nsamples = 27\\nvalue = [0, 1, 25, 1, 0, 0]'),\n",
              " Text(88.25510204081634, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(90.5326530612245, 113.66181818181819, 'X[9] <= 0.71\\ngini = 0.074\\nsamples = 26\\nvalue = [0, 0, 25, 1, 0, 0]'),\n",
              " Text(89.39387755102042, 103.77818181818182, 'gini = 0.0\\nsamples = 25\\nvalue = [0, 0, 25, 0, 0, 0]'),\n",
              " Text(91.67142857142858, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(100.2122448979592, 133.42909090909092, 'X[6] <= 51.0\\ngini = 0.535\\nsamples = 29\\nvalue = [0, 1, 10, 17, 1, 0]'),\n",
              " Text(97.36530612244898, 123.54545454545455, 'X[8] <= 3.405\\ngini = 0.41\\nsamples = 19\\nvalue = [0, 0, 4, 14, 1, 0]'),\n",
              " Text(95.08775510204083, 113.66181818181819, 'X[7] <= 1.0\\ngini = 0.24\\nsamples = 15\\nvalue = [0, 0, 1, 13, 1, 0]'),\n",
              " Text(93.94897959183675, 103.77818181818182, 'X[2] <= 0.3\\ngini = 0.133\\nsamples = 14\\nvalue = [0, 0, 0, 13, 1, 0]'),\n",
              " Text(92.81020408163266, 93.89454545454547, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 0, 13, 0, 0]'),\n",
              " Text(95.08775510204083, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(96.2265306122449, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(99.64285714285715, 113.66181818181819, 'X[2] <= 0.18\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1, 0, 0]'),\n",
              " Text(98.50408163265307, 103.77818181818182, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(100.78163265306124, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(103.05918367346939, 123.54545454545455, 'X[9] <= 0.615\\ngini = 0.54\\nsamples = 10\\nvalue = [0, 1, 6, 3, 0, 0]'),\n",
              " Text(101.92040816326532, 113.66181818181819, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(104.19795918367348, 113.66181818181819, 'X[6] <= 62.0\\ngini = 0.56\\nsamples = 5\\nvalue = [0, 1, 1, 3, 0, 0]'),\n",
              " Text(103.05918367346939, 103.77818181818182, 'X[0] <= 7.95\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1, 0, 0, 0]'),\n",
              " Text(101.92040816326532, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(104.19795918367348, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(105.33673469387756, 103.77818181818182, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(112.73877551020409, 143.31272727272727, 'X[5] <= 7.5\\ngini = 0.292\\nsamples = 53\\nvalue = [0, 0, 44, 7, 2, 0]'),\n",
              " Text(109.89183673469388, 133.42909090909092, 'X[7] <= 0.997\\ngini = 0.595\\nsamples = 11\\nvalue = [0, 0, 6, 3, 2, 0]'),\n",
              " Text(107.61428571428573, 123.54545454545455, 'X[1] <= 0.818\\ngini = 0.245\\nsamples = 7\\nvalue = [0, 0, 6, 0, 1, 0]'),\n",
              " Text(106.47551020408164, 113.66181818181819, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6, 0, 0, 0]'),\n",
              " Text(108.75306122448981, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(112.16938775510205, 123.54545454545455, 'X[8] <= 3.345\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 0, 3, 1, 0]'),\n",
              " Text(111.03061224489797, 113.66181818181819, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(113.30816326530613, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(115.5857142857143, 133.42909090909092, 'X[8] <= 2.962\\ngini = 0.172\\nsamples = 42\\nvalue = [0, 0, 38, 4, 0, 0]'),\n",
              " Text(114.44693877551022, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(116.72448979591837, 123.54545454545455, 'X[7] <= 0.996\\ngini = 0.136\\nsamples = 41\\nvalue = [0, 0, 38, 3, 0, 0]'),\n",
              " Text(115.5857142857143, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(117.86326530612246, 113.66181818181819, 'X[6] <= 46.5\\ngini = 0.095\\nsamples = 40\\nvalue = [0, 0, 38, 2, 0, 0]'),\n",
              " Text(116.72448979591837, 103.77818181818182, 'X[6] <= 45.5\\ngini = 0.245\\nsamples = 14\\nvalue = [0, 0, 12, 2, 0, 0]'),\n",
              " Text(115.5857142857143, 93.89454545454547, 'X[10] <= 9.15\\ngini = 0.142\\nsamples = 13\\nvalue = [0, 0, 12, 1, 0, 0]'),\n",
              " Text(114.44693877551022, 84.01090909090911, 'X[5] <= 11.5\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1, 0, 0]'),\n",
              " Text(113.30816326530613, 74.12727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(115.5857142857143, 74.12727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(116.72448979591837, 84.01090909090911, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11, 0, 0, 0]'),\n",
              " Text(117.86326530612246, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(119.00204081632654, 103.77818181818182, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 0, 26, 0, 0, 0]'),\n",
              " Text(120.14081632653063, 163.07999999999998, 'X[8] <= 3.005\\ngini = 0.235\\nsamples = 60\\nvalue = [0, 1, 52, 7, 0, 0]'),\n",
              " Text(117.86326530612246, 153.19636363636363, 'X[2] <= 0.285\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 1, 3, 0, 0]'),\n",
              " Text(116.72448979591837, 143.31272727272727, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(119.00204081632654, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(122.4183673469388, 153.19636363636363, 'X[3] <= 1.6\\ngini = 0.165\\nsamples = 56\\nvalue = [0, 1, 51, 4, 0, 0]'),\n",
              " Text(121.27959183673471, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(123.55714285714286, 143.31272727272727, 'X[4] <= 0.067\\ngini = 0.135\\nsamples = 55\\nvalue = [0, 0, 51, 4, 0, 0]'),\n",
              " Text(122.4183673469388, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(124.69591836734695, 133.42909090909092, 'X[4] <= 0.076\\ngini = 0.105\\nsamples = 54\\nvalue = [0, 0, 51, 3, 0, 0]'),\n",
              " Text(121.27959183673471, 123.54545454545455, 'X[9] <= 0.555\\ngini = 0.408\\nsamples = 7\\nvalue = [0, 0, 5, 2, 0, 0]'),\n",
              " Text(120.14081632653063, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(122.4183673469388, 113.66181818181819, 'X[6] <= 96.0\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 0, 5, 1, 0, 0]'),\n",
              " Text(121.27959183673471, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(123.55714285714286, 103.77818181818182, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(128.1122448979592, 123.54545454545455, 'X[6] <= 98.5\\ngini = 0.042\\nsamples = 47\\nvalue = [0, 0, 46, 1, 0, 0]'),\n",
              " Text(126.97346938775512, 113.66181818181819, 'X[6] <= 97.0\\ngini = 0.198\\nsamples = 9\\nvalue = [0, 0, 8, 1, 0, 0]'),\n",
              " Text(125.83469387755103, 103.77818181818182, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7, 0, 0, 0]'),\n",
              " Text(128.1122448979592, 103.77818181818182, 'X[0] <= 8.25\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1, 0, 0]'),\n",
              " Text(126.97346938775512, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(129.25102040816327, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(129.25102040816327, 113.66181818181819, 'gini = 0.0\\nsamples = 38\\nvalue = [0, 0, 38, 0, 0, 0]'),\n",
              " Text(138.64591836734695, 172.96363636363637, 'X[2] <= 0.485\\ngini = 0.622\\nsamples = 60\\nvalue = [3, 1, 22, 29, 5, 0]'),\n",
              " Text(134.9448979591837, 163.07999999999998, 'X[1] <= 0.615\\ngini = 0.482\\nsamples = 30\\nvalue = [1, 0, 8, 20, 1, 0]'),\n",
              " Text(132.66734693877552, 153.19636363636363, 'X[9] <= 0.835\\ngini = 0.426\\nsamples = 26\\nvalue = [1, 0, 5, 19, 1, 0]'),\n",
              " Text(131.52857142857144, 143.31272727272727, 'X[9] <= 0.555\\ngini = 0.381\\nsamples = 25\\nvalue = [0, 0, 5, 19, 1, 0]'),\n",
              " Text(130.38979591836735, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(132.66734693877552, 133.42909090909092, 'X[4] <= 0.062\\ngini = 0.344\\nsamples = 24\\nvalue = [0, 0, 4, 19, 1, 0]'),\n",
              " Text(131.52857142857144, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(133.8061224489796, 123.54545454545455, 'X[3] <= 2.25\\ngini = 0.299\\nsamples = 23\\nvalue = [0, 0, 3, 19, 1, 0]'),\n",
              " Text(132.66734693877552, 113.66181818181819, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 0, 0, 10, 0, 0]'),\n",
              " Text(134.9448979591837, 113.66181818181819, 'X[7] <= 0.999\\ngini = 0.462\\nsamples = 13\\nvalue = [0, 0, 3, 9, 1, 0]'),\n",
              " Text(132.66734693877552, 103.77818181818182, 'X[7] <= 0.998\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 0, 1, 0]'),\n",
              " Text(131.52857142857144, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(133.8061224489796, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(137.22244897959186, 103.77818181818182, 'X[0] <= 10.55\\ngini = 0.18\\nsamples = 10\\nvalue = [0, 0, 1, 9, 0, 0]'),\n",
              " Text(136.08367346938778, 93.89454545454547, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 0, 8, 0, 0]'),\n",
              " Text(138.36122448979594, 93.89454545454547, 'X[1] <= 0.545\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1, 0, 0]'),\n",
              " Text(137.22244897959186, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(139.5, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(133.8061224489796, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0, 0]'),\n",
              " Text(137.22244897959186, 153.19636363636363, 'X[4] <= 0.078\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1, 0, 0]'),\n",
              " Text(136.08367346938778, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(138.36122448979594, 143.31272727272727, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(142.3469387755102, 163.07999999999998, 'X[3] <= 1.7\\ngini = 0.669\\nsamples = 30\\nvalue = [2, 1, 14, 9, 4, 0]'),\n",
              " Text(141.20816326530613, 153.19636363636363, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(143.4857142857143, 153.19636363636363, 'X[8] <= 3.035\\ngini = 0.635\\nsamples = 28\\nvalue = [2, 1, 14, 9, 2, 0]'),\n",
              " Text(142.3469387755102, 143.31272727272727, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(144.62448979591838, 143.31272727272727, 'X[0] <= 12.125\\ngini = 0.677\\nsamples = 23\\nvalue = [2, 1, 9, 9, 2, 0]'),\n",
              " Text(141.77755102040817, 133.42909090909092, 'X[1] <= 0.577\\ngini = 0.602\\nsamples = 16\\nvalue = [2, 1, 9, 4, 0, 0]'),\n",
              " Text(139.5, 123.54545454545455, 'X[5] <= 18.5\\ngini = 0.32\\nsamples = 10\\nvalue = [0, 0, 8, 2, 0, 0]'),\n",
              " Text(138.36122448979594, 113.66181818181819, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7, 0, 0, 0]'),\n",
              " Text(140.63877551020408, 113.66181818181819, 'X[10] <= 9.55\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 1, 2, 0, 0]'),\n",
              " Text(139.5, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(141.77755102040817, 103.77818181818182, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(144.05510204081634, 123.54545454545455, 'X[10] <= 9.25\\ngini = 0.722\\nsamples = 6\\nvalue = [2, 1, 1, 2, 0, 0]'),\n",
              " Text(142.91632653061225, 113.66181818181819, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0, 0, 0, 0]'),\n",
              " Text(145.19387755102042, 113.66181818181819, 'X[9] <= 0.595\\ngini = 0.625\\nsamples = 4\\nvalue = [0, 1, 1, 2, 0, 0]'),\n",
              " Text(144.05510204081634, 103.77818181818182, 'X[1] <= 0.585\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1, 0, 0, 0]'),\n",
              " Text(142.91632653061225, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(145.19387755102042, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(146.3326530612245, 103.77818181818182, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(147.4714285714286, 133.42909090909092, 'X[3] <= 3.425\\ngini = 0.408\\nsamples = 7\\nvalue = [0, 0, 0, 5, 2, 0]'),\n",
              " Text(146.3326530612245, 123.54545454545455, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 5, 0, 0]'),\n",
              " Text(148.61020408163267, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(253.95138711734697, 202.61454545454546, 'X[10] <= 11.45\\ngini = 0.65\\nsamples = 516\\nvalue = [2, 17, 114, 259, 112, 12]'),\n",
              " Text(207.94218750000002, 192.73090909090908, 'X[6] <= 97.0\\ngini = 0.637\\nsamples = 318\\nvalue = [2, 13, 99, 157, 46, 1]'),\n",
              " Text(206.80341198979593, 182.84727272727272, 'X[9] <= 0.645\\ngini = 0.633\\nsamples = 309\\nvalue = [2, 13, 90, 157, 46, 1]'),\n",
              " Text(169.4106505102041, 172.96363636363637, 'X[8] <= 3.165\\ngini = 0.63\\nsamples = 157\\nvalue = [2, 12, 63, 70, 10, 0]'),\n",
              " Text(153.16530612244898, 163.07999999999998, 'X[9] <= 0.5\\ngini = 0.32\\nsamples = 16\\nvalue = [0, 1, 13, 2, 0, 0]'),\n",
              " Text(152.02653061224493, 153.19636363636363, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(154.30408163265307, 153.19636363636363, 'X[2] <= 0.67\\ngini = 0.24\\nsamples = 15\\nvalue = [0, 1, 13, 1, 0, 0]'),\n",
              " Text(153.16530612244898, 143.31272727272727, 'X[4] <= 0.073\\ngini = 0.133\\nsamples = 14\\nvalue = [0, 1, 13, 0, 0, 0]'),\n",
              " Text(152.02653061224493, 133.42909090909092, 'X[9] <= 0.585\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1, 0, 0, 0]'),\n",
              " Text(150.88775510204084, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(153.16530612244898, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(154.30408163265307, 133.42909090909092, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12, 0, 0, 0]'),\n",
              " Text(155.44285714285715, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(185.6559948979592, 163.07999999999998, 'X[5] <= 12.5\\ngini = 0.63\\nsamples = 141\\nvalue = [2, 11, 50, 68, 10, 0]'),\n",
              " Text(168.32525510204084, 153.19636363636363, 'X[3] <= 1.85\\ngini = 0.703\\nsamples = 73\\nvalue = [2, 8, 29, 24, 10, 0]'),\n",
              " Text(158.8591836734694, 143.31272727272727, 'X[8] <= 3.37\\ngini = 0.475\\nsamples = 18\\nvalue = [0, 0, 12, 1, 5, 0]'),\n",
              " Text(156.58163265306123, 133.42909090909092, 'X[2] <= 0.405\\ngini = 0.469\\nsamples = 8\\nvalue = [0, 0, 3, 0, 5, 0]'),\n",
              " Text(155.44285714285715, 123.54545454545455, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 0, 5, 0]'),\n",
              " Text(157.72040816326532, 123.54545454545455, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(161.13673469387757, 133.42909090909092, 'X[5] <= 8.5\\ngini = 0.18\\nsamples = 10\\nvalue = [0, 0, 9, 1, 0, 0]'),\n",
              " Text(159.9979591836735, 123.54545454545455, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9, 0, 0, 0]'),\n",
              " Text(162.27551020408166, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(177.79132653061225, 143.31272727272727, 'X[1] <= 0.655\\ngini = 0.699\\nsamples = 55\\nvalue = [2, 8, 17, 23, 5, 0]'),\n",
              " Text(168.82346938775513, 133.42909090909092, 'X[0] <= 7.2\\ngini = 0.611\\nsamples = 39\\nvalue = [0, 2, 11, 21, 5, 0]'),\n",
              " Text(164.55306122448982, 123.54545454545455, 'X[4] <= 0.061\\ngini = 0.716\\nsamples = 9\\nvalue = [0, 2, 3, 1, 3, 0]'),\n",
              " Text(163.41428571428574, 113.66181818181819, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0]'),\n",
              " Text(165.69183673469388, 113.66181818181819, 'X[9] <= 0.56\\ngini = 0.611\\nsamples = 6\\nvalue = [0, 2, 3, 1, 0, 0]'),\n",
              " Text(164.55306122448982, 103.77818181818182, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(166.83061224489796, 103.77818181818182, 'X[3] <= 2.3\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 0, 1, 0, 0]'),\n",
              " Text(165.69183673469388, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0, 0, 0, 0]'),\n",
              " Text(167.96938775510205, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(173.09387755102043, 123.54545454545455, 'X[7] <= 0.996\\ngini = 0.48\\nsamples = 30\\nvalue = [0, 0, 8, 20, 2, 0]'),\n",
              " Text(170.24693877551022, 113.66181818181819, 'X[7] <= 0.994\\ngini = 0.153\\nsamples = 12\\nvalue = [0, 0, 0, 11, 1, 0]'),\n",
              " Text(169.10816326530613, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(171.3857142857143, 103.77818181818182, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 0, 11, 0, 0]'),\n",
              " Text(175.94081632653064, 113.66181818181819, 'X[4] <= 0.09\\ngini = 0.549\\nsamples = 18\\nvalue = [0, 0, 8, 9, 1, 0]'),\n",
              " Text(173.66326530612247, 103.77818181818182, 'X[3] <= 3.3\\ngini = 0.346\\nsamples = 9\\nvalue = [0, 0, 2, 7, 0, 0]'),\n",
              " Text(172.52448979591838, 93.89454545454547, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 0, 6, 0, 0]'),\n",
              " Text(174.80204081632655, 93.89454545454547, 'X[7] <= 0.998\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 1, 0, 0]'),\n",
              " Text(173.66326530612247, 84.01090909090911, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(175.94081632653064, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(178.2183673469388, 103.77818181818182, 'X[3] <= 2.7\\ngini = 0.494\\nsamples = 9\\nvalue = [0, 0, 6, 2, 1, 0]'),\n",
              " Text(177.07959183673472, 93.89454545454547, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(179.35714285714286, 93.89454545454547, 'X[0] <= 10.65\\ngini = 0.625\\nsamples = 4\\nvalue = [0, 0, 1, 2, 1, 0]'),\n",
              " Text(178.2183673469388, 84.01090909090911, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(180.49591836734695, 84.01090909090911, 'X[6] <= 23.5\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 0, 1, 0]'),\n",
              " Text(179.35714285714286, 74.12727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(181.63469387755103, 74.12727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(186.7591836734694, 133.42909090909092, 'X[10] <= 10.85\\ngini = 0.688\\nsamples = 16\\nvalue = [2, 6, 6, 2, 0, 0]'),\n",
              " Text(183.9122448979592, 123.54545454545455, 'X[1] <= 0.89\\ngini = 0.531\\nsamples = 8\\nvalue = [1, 0, 5, 2, 0, 0]'),\n",
              " Text(181.63469387755103, 113.66181818181819, 'X[7] <= 0.998\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 0, 5, 1, 0, 0]'),\n",
              " Text(180.49591836734695, 103.77818181818182, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(182.7734693877551, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(186.18979591836737, 113.66181818181819, 'X[7] <= 0.996\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 0, 1, 0, 0]'),\n",
              " Text(185.05102040816328, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(187.32857142857145, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0, 0]'),\n",
              " Text(189.60612244897962, 123.54545454545455, 'X[2] <= 0.005\\ngini = 0.406\\nsamples = 8\\nvalue = [1, 6, 1, 0, 0, 0]'),\n",
              " Text(188.46734693877553, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(190.7448979591837, 113.66181818181819, 'X[9] <= 0.52\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 6, 0, 0, 0, 0]'),\n",
              " Text(189.60612244897962, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0, 0]'),\n",
              " Text(191.8836734693878, 103.77818181818182, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0, 0, 0, 0]'),\n",
              " Text(202.98673469387757, 153.19636363636363, 'X[6] <= 43.5\\ngini = 0.484\\nsamples = 68\\nvalue = [0, 3, 21, 44, 0, 0]'),\n",
              " Text(195.3, 143.31272727272727, 'X[9] <= 0.5\\ngini = 0.329\\nsamples = 36\\nvalue = [0, 2, 5, 29, 0, 0]'),\n",
              " Text(193.02244897959184, 133.42909090909092, 'X[4] <= 0.066\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1, 0, 0]'),\n",
              " Text(191.8836734693878, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(194.16122448979593, 123.54545454545455, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(197.57755102040818, 133.42909090909092, 'X[10] <= 10.35\\ngini = 0.227\\nsamples = 32\\nvalue = [0, 2, 2, 28, 0, 0]'),\n",
              " Text(196.4387755102041, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(198.71632653061226, 123.54545454545455, 'X[4] <= 0.069\\ngini = 0.179\\nsamples = 31\\nvalue = [0, 2, 1, 28, 0, 0]'),\n",
              " Text(197.57755102040818, 113.66181818181819, 'X[6] <= 26.0\\ngini = 0.611\\nsamples = 6\\nvalue = [0, 2, 1, 3, 0, 0]'),\n",
              " Text(196.4387755102041, 103.77818181818182, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(198.71632653061226, 103.77818181818182, 'X[10] <= 11.2\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1, 0, 0, 0]'),\n",
              " Text(197.57755102040818, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0, 0, 0, 0]'),\n",
              " Text(199.85510204081635, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(199.85510204081635, 113.66181818181819, 'gini = 0.0\\nsamples = 25\\nvalue = [0, 0, 0, 25, 0, 0]'),\n",
              " Text(210.67346938775512, 143.31272727272727, 'X[6] <= 62.0\\ngini = 0.529\\nsamples = 32\\nvalue = [0, 1, 16, 15, 0, 0]'),\n",
              " Text(206.68775510204082, 133.42909090909092, 'X[5] <= 32.5\\ngini = 0.42\\nsamples = 20\\nvalue = [0, 0, 14, 6, 0, 0]'),\n",
              " Text(205.54897959183674, 123.54545454545455, 'X[3] <= 2.05\\ngini = 0.346\\nsamples = 18\\nvalue = [0, 0, 14, 4, 0, 0]'),\n",
              " Text(202.13265306122452, 113.66181818181819, 'X[5] <= 27.5\\ngini = 0.153\\nsamples = 12\\nvalue = [0, 0, 11, 1, 0, 0]'),\n",
              " Text(200.99387755102043, 103.77818181818182, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9, 0, 0, 0]'),\n",
              " Text(203.2714285714286, 103.77818181818182, 'X[5] <= 28.5\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 1, 0, 0]'),\n",
              " Text(202.13265306122452, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(204.41020408163268, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(208.965306122449, 113.66181818181819, 'X[9] <= 0.605\\ngini = 0.5\\nsamples = 6\\nvalue = [0, 0, 3, 3, 0, 0]'),\n",
              " Text(207.8265306122449, 103.77818181818182, 'X[9] <= 0.47\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 1, 3, 0, 0]'),\n",
              " Text(206.68775510204082, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(208.965306122449, 93.89454545454547, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(210.10408163265308, 103.77818181818182, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(207.8265306122449, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(214.6591836734694, 133.42909090909092, 'X[3] <= 1.7\\ngini = 0.403\\nsamples = 12\\nvalue = [0, 1, 2, 9, 0, 0]'),\n",
              " Text(212.38163265306125, 123.54545454545455, 'X[6] <= 76.0\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1, 0, 0, 0]'),\n",
              " Text(211.24285714285716, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(213.52040816326533, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(216.93673469387758, 123.54545454545455, 'X[1] <= 0.792\\ngini = 0.18\\nsamples = 10\\nvalue = [0, 0, 1, 9, 0, 0]'),\n",
              " Text(215.7979591836735, 113.66181818181819, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 0, 9, 0, 0]'),\n",
              " Text(218.07551020408167, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(244.1961734693878, 172.96363636363637, 'X[1] <= 0.375\\ngini = 0.585\\nsamples = 152\\nvalue = [0, 1, 27, 87, 36, 1]'),\n",
              " Text(228.89387755102044, 163.07999999999998, 'X[4] <= 0.061\\ngini = 0.621\\nsamples = 63\\nvalue = [0, 0, 10, 27, 26, 0]'),\n",
              " Text(220.3530612244898, 153.19636363636363, 'X[0] <= 8.05\\ngini = 0.379\\nsamples = 13\\nvalue = [0, 0, 1, 2, 10, 0]'),\n",
              " Text(219.21428571428572, 143.31272727272727, 'X[7] <= 0.996\\ngini = 0.625\\nsamples = 4\\nvalue = [0, 0, 1, 2, 1, 0]'),\n",
              " Text(218.07551020408167, 133.42909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(220.3530612244898, 133.42909090909092, 'X[9] <= 0.845\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 0, 1, 0]'),\n",
              " Text(219.21428571428572, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(221.4918367346939, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(221.4918367346939, 143.31272727272727, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 0, 0, 9, 0]'),\n",
              " Text(237.43469387755104, 153.19636363636363, 'X[0] <= 10.45\\ngini = 0.615\\nsamples = 50\\nvalue = [0, 0, 9, 25, 16, 0]'),\n",
              " Text(230.60204081632656, 143.31272727272727, 'X[0] <= 8.1\\ngini = 0.576\\nsamples = 38\\nvalue = [0, 0, 8, 22, 8, 0]'),\n",
              " Text(226.04693877551023, 133.42909090909092, 'X[1] <= 0.355\\ngini = 0.667\\nsamples = 15\\nvalue = [0, 0, 5, 5, 5, 0]'),\n",
              " Text(223.76938775510206, 123.54545454545455, 'X[2] <= 0.46\\ngini = 0.58\\nsamples = 10\\nvalue = [0, 0, 4, 5, 1, 0]'),\n",
              " Text(222.63061224489797, 113.66181818181819, 'X[3] <= 2.35\\ngini = 0.571\\nsamples = 7\\nvalue = [0, 0, 4, 2, 1, 0]'),\n",
              " Text(221.4918367346939, 103.77818181818182, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0]'),\n",
              " Text(223.76938775510206, 103.77818181818182, 'X[6] <= 35.0\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 0, 2, 1, 0]'),\n",
              " Text(222.63061224489797, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(224.90816326530614, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(224.90816326530614, 113.66181818181819, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(228.3244897959184, 123.54545454545455, 'X[4] <= 0.08\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 0, 1, 0, 4, 0]'),\n",
              " Text(227.1857142857143, 113.66181818181819, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 0, 4, 0]'),\n",
              " Text(229.46326530612248, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(235.15714285714287, 133.42909090909092, 'X[2] <= 0.515\\ngini = 0.42\\nsamples = 23\\nvalue = [0, 0, 3, 17, 3, 0]'),\n",
              " Text(232.8795918367347, 123.54545454545455, 'X[9] <= 0.67\\ngini = 0.278\\nsamples = 18\\nvalue = [0, 0, 0, 15, 3, 0]'),\n",
              " Text(231.74081632653065, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(234.0183673469388, 113.66181818181819, 'X[5] <= 41.5\\ngini = 0.208\\nsamples = 17\\nvalue = [0, 0, 0, 15, 2, 0]'),\n",
              " Text(232.8795918367347, 103.77818181818182, 'X[0] <= 9.7\\ngini = 0.117\\nsamples = 16\\nvalue = [0, 0, 0, 15, 1, 0]'),\n",
              " Text(231.74081632653065, 93.89454545454547, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 0, 13, 0, 0]'),\n",
              " Text(234.0183673469388, 93.89454545454547, 'X[2] <= 0.415\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 0, 2, 1, 0]'),\n",
              " Text(232.8795918367347, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(235.15714285714287, 84.01090909090911, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(235.15714285714287, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(237.43469387755104, 123.54545454545455, 'X[8] <= 3.225\\ngini = 0.48\\nsamples = 5\\nvalue = [0, 0, 3, 2, 0, 0]'),\n",
              " Text(236.29591836734696, 113.66181818181819, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(238.57346938775513, 113.66181818181819, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(244.26734693877555, 143.31272727272727, 'X[1] <= 0.335\\ngini = 0.486\\nsamples = 12\\nvalue = [0, 0, 1, 3, 8, 0]'),\n",
              " Text(243.12857142857146, 133.42909090909092, 'X[6] <= 21.5\\ngini = 0.34\\nsamples = 10\\nvalue = [0, 0, 1, 1, 8, 0]'),\n",
              " Text(241.98979591836738, 123.54545454545455, 'X[8] <= 3.28\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1, 0, 0]'),\n",
              " Text(240.8510204081633, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(243.12857142857146, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(244.26734693877555, 123.54545454545455, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 0, 0, 8, 0]'),\n",
              " Text(245.4061224489796, 133.42909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(259.4984693877551, 163.07999999999998, 'X[3] <= 3.475\\ngini = 0.496\\nsamples = 89\\nvalue = [0, 1, 17, 60, 10, 1]'),\n",
              " Text(253.6622448979592, 153.19636363636363, 'X[7] <= 0.996\\ngini = 0.415\\nsamples = 78\\nvalue = [0, 0, 12, 58, 7, 1]'),\n",
              " Text(248.82244897959185, 143.31272727272727, 'X[4] <= 0.119\\ngini = 0.263\\nsamples = 34\\nvalue = [0, 0, 1, 29, 3, 1]'),\n",
              " Text(247.68367346938777, 133.42909090909092, 'X[2] <= 0.16\\ngini = 0.222\\nsamples = 33\\nvalue = [0, 0, 1, 29, 2, 1]'),\n",
              " Text(246.5448979591837, 123.54545454545455, 'gini = 0.0\\nsamples = 21\\nvalue = [0, 0, 0, 21, 0, 0]'),\n",
              " Text(248.82244897959185, 123.54545454545455, 'X[9] <= 0.815\\ngini = 0.514\\nsamples = 12\\nvalue = [0, 0, 1, 8, 2, 1]'),\n",
              " Text(247.68367346938777, 113.66181818181819, 'X[10] <= 11.15\\ngini = 0.72\\nsamples = 5\\nvalue = [0, 0, 1, 1, 2, 1]'),\n",
              " Text(245.4061224489796, 103.77818181818182, 'X[4] <= 0.077\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 0, 1, 2, 0]'),\n",
              " Text(244.26734693877555, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(246.5448979591837, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(249.96122448979594, 103.77818181818182, 'X[6] <= 28.5\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 0, 0, 1]'),\n",
              " Text(248.82244897959185, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(251.10000000000002, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(249.96122448979594, 113.66181818181819, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 0, 7, 0, 0]'),\n",
              " Text(249.96122448979594, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(258.50204081632654, 143.31272727272727, 'X[8] <= 3.46\\ngini = 0.495\\nsamples = 44\\nvalue = [0, 0, 11, 29, 4, 0]'),\n",
              " Text(256.2244897959184, 133.42909090909092, 'X[3] <= 1.55\\ngini = 0.46\\nsamples = 40\\nvalue = [0, 0, 8, 28, 4, 0]'),\n",
              " Text(255.08571428571432, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(257.36326530612246, 123.54545454545455, 'X[7] <= 0.997\\ngini = 0.437\\nsamples = 39\\nvalue = [0, 0, 8, 28, 3, 0]'),\n",
              " Text(253.3775510204082, 113.66181818181819, 'X[4] <= 0.067\\ngini = 0.642\\nsamples = 9\\nvalue = [0, 0, 3, 4, 2, 0]'),\n",
              " Text(252.2387755102041, 103.77818181818182, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(254.51632653061228, 103.77818181818182, 'X[2] <= 0.21\\ngini = 0.49\\nsamples = 7\\nvalue = [0, 0, 3, 4, 0, 0]'),\n",
              " Text(253.3775510204082, 93.89454545454547, 'X[9] <= 0.695\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 0, 1, 4, 0, 0]'),\n",
              " Text(252.2387755102041, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(254.51632653061228, 84.01090909090911, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 4, 0, 0]'),\n",
              " Text(255.65510204081636, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(261.3489795918368, 113.66181818181819, 'X[9] <= 0.865\\ngini = 0.331\\nsamples = 30\\nvalue = [0, 0, 5, 24, 1, 0]'),\n",
              " Text(259.0714285714286, 103.77818181818182, 'X[6] <= 71.0\\ngini = 0.261\\nsamples = 27\\nvalue = [0, 0, 3, 23, 1, 0]'),\n",
              " Text(257.9326530612245, 93.89454545454547, 'X[4] <= 0.089\\ngini = 0.21\\nsamples = 26\\nvalue = [0, 0, 2, 23, 1, 0]'),\n",
              " Text(256.79387755102044, 84.01090909090911, 'gini = 0.0\\nsamples = 17\\nvalue = [0, 0, 0, 17, 0, 0]'),\n",
              " Text(259.0714285714286, 84.01090909090911, 'X[2] <= 0.395\\ngini = 0.494\\nsamples = 9\\nvalue = [0, 0, 2, 6, 1, 0]'),\n",
              " Text(257.9326530612245, 74.12727272727273, 'X[4] <= 0.095\\ngini = 0.625\\nsamples = 4\\nvalue = [0, 0, 2, 1, 1, 0]'),\n",
              " Text(256.79387755102044, 64.24363636363637, 'X[4] <= 0.091\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 0, 1, 1, 0]'),\n",
              " Text(255.65510204081636, 54.360000000000014, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(257.9326530612245, 54.360000000000014, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(259.0714285714286, 64.24363636363637, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(260.2102040816327, 74.12727272727273, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 5, 0, 0]'),\n",
              " Text(260.2102040816327, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(263.62653061224495, 103.77818181818182, 'X[7] <= 1.0\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 2, 1, 0, 0]'),\n",
              " Text(262.48775510204086, 93.89454545454547, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(264.76530612244903, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(260.7795918367347, 133.42909090909092, 'X[4] <= 0.076\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1, 0, 0]'),\n",
              " Text(259.6408163265306, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(261.9183673469388, 123.54545454545455, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(265.33469387755105, 153.19636363636363, 'X[1] <= 0.425\\ngini = 0.678\\nsamples = 11\\nvalue = [0, 1, 5, 2, 3, 0]'),\n",
              " Text(264.19591836734696, 143.31272727272727, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0]'),\n",
              " Text(266.47346938775513, 143.31272727272727, 'X[9] <= 0.735\\ngini = 0.531\\nsamples = 8\\nvalue = [0, 1, 5, 2, 0, 0]'),\n",
              " Text(265.33469387755105, 133.42909090909092, 'X[4] <= 0.103\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 0, 2, 0, 0]'),\n",
              " Text(264.19591836734696, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(266.47346938775513, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(267.6122448979592, 133.42909090909092, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5, 0, 0, 0]'),\n",
              " Text(209.0809630102041, 182.84727272727272, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9, 0, 0, 0]'),\n",
              " Text(299.9605867346939, 192.73090909090908, 'X[0] <= 7.85\\ngini = 0.614\\nsamples = 198\\nvalue = [0, 4, 15, 102, 66, 11]'),\n",
              " Text(280.20994897959184, 182.84727272727272, 'X[2] <= 0.355\\ngini = 0.549\\nsamples = 90\\nvalue = [0, 3, 10, 57, 17, 3]'),\n",
              " Text(279.07117346938776, 172.96363636363637, 'X[9] <= 0.86\\ngini = 0.605\\nsamples = 77\\nvalue = [0, 3, 10, 44, 17, 3]'),\n",
              " Text(277.9323979591837, 163.07999999999998, 'X[6] <= 15.0\\ngini = 0.589\\nsamples = 74\\nvalue = [0, 3, 10, 44, 14, 3]'),\n",
              " Text(269.8897959183674, 153.19636363636363, 'X[3] <= 1.75\\ngini = 0.542\\nsamples = 12\\nvalue = [0, 0, 1, 4, 7, 0]'),\n",
              " Text(268.7510204081633, 143.31272727272727, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(271.02857142857147, 143.31272727272727, 'X[7] <= 0.996\\ngini = 0.37\\nsamples = 9\\nvalue = [0, 0, 1, 1, 7, 0]'),\n",
              " Text(269.8897959183674, 133.42909090909092, 'X[8] <= 3.335\\ngini = 0.219\\nsamples = 8\\nvalue = [0, 0, 0, 1, 7, 0]'),\n",
              " Text(268.7510204081633, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(271.02857142857147, 123.54545454545455, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 0, 0, 7, 0]'),\n",
              " Text(272.16734693877555, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(285.975, 153.19636363636363, 'X[6] <= 78.5\\ngini = 0.545\\nsamples = 62\\nvalue = [0, 3, 9, 40, 7, 3]'),\n",
              " Text(279.28469387755104, 143.31272727272727, 'X[6] <= 27.5\\ngini = 0.442\\nsamples = 52\\nvalue = [0, 2, 6, 38, 5, 1]'),\n",
              " Text(274.4448979591837, 133.42909090909092, 'X[0] <= 6.35\\ngini = 0.551\\nsamples = 15\\nvalue = [0, 1, 6, 8, 0, 0]'),\n",
              " Text(273.30612244897964, 123.54545454545455, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0]'),\n",
              " Text(275.5836734693878, 123.54545454545455, 'X[3] <= 3.325\\ngini = 0.43\\nsamples = 11\\nvalue = [0, 1, 2, 8, 0, 0]'),\n",
              " Text(273.30612244897964, 113.66181818181819, 'X[3] <= 1.775\\ngini = 0.198\\nsamples = 9\\nvalue = [0, 0, 1, 8, 0, 0]'),\n",
              " Text(272.16734693877555, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(274.4448979591837, 103.77818181818182, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 0, 8, 0, 0]'),\n",
              " Text(277.861224489796, 113.66181818181819, 'X[8] <= 3.44\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1, 0, 0, 0]'),\n",
              " Text(276.7224489795919, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(279.0, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(284.1244897959184, 133.42909090909092, 'X[0] <= 4.95\\ngini = 0.323\\nsamples = 37\\nvalue = [0, 1, 0, 30, 5, 1]'),\n",
              " Text(281.27755102040817, 123.54545454545455, 'X[9] <= 0.65\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 0, 0, 1, 0]'),\n",
              " Text(280.1387755102041, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(282.41632653061225, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(286.9714285714286, 123.54545454545455, 'X[1] <= 0.8\\ngini = 0.251\\nsamples = 35\\nvalue = [0, 0, 0, 30, 4, 1]'),\n",
              " Text(284.6938775510204, 113.66181818181819, 'X[8] <= 3.27\\ngini = 0.174\\nsamples = 32\\nvalue = [0, 0, 0, 29, 2, 1]'),\n",
              " Text(283.55510204081634, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(285.8326530612245, 103.77818181818182, 'X[0] <= 5.05\\ngini = 0.123\\nsamples = 31\\nvalue = [0, 0, 0, 29, 1, 1]'),\n",
              " Text(283.55510204081634, 93.89454545454547, 'X[2] <= 0.125\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 0, 2, 0, 1]'),\n",
              " Text(282.41632653061225, 84.01090909090911, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(284.6938775510204, 84.01090909090911, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(288.1102040816327, 93.89454545454547, 'X[6] <= 30.0\\ngini = 0.069\\nsamples = 28\\nvalue = [0, 0, 0, 27, 1, 0]'),\n",
              " Text(286.9714285714286, 84.01090909090911, 'X[10] <= 11.9\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 0, 0, 4, 1, 0]'),\n",
              " Text(285.8326530612245, 74.12727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(288.1102040816327, 74.12727272727273, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 4, 0, 0]'),\n",
              " Text(289.24897959183676, 84.01090909090911, 'gini = 0.0\\nsamples = 23\\nvalue = [0, 0, 0, 23, 0, 0]'),\n",
              " Text(289.24897959183676, 113.66181818181819, 'X[2] <= 0.05\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 0, 1, 2, 0]'),\n",
              " Text(288.1102040816327, 103.77818181818182, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(290.38775510204084, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(292.665306122449, 143.31272727272727, 'X[2] <= 0.07\\ngini = 0.78\\nsamples = 10\\nvalue = [0, 1, 3, 2, 2, 2]'),\n",
              " Text(290.38775510204084, 133.42909090909092, 'X[1] <= 0.485\\ngini = 0.5\\nsamples = 4\\nvalue = [0, 0, 0, 0, 2, 2]'),\n",
              " Text(289.24897959183676, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(291.5265306122449, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 0, 2]'),\n",
              " Text(294.9428571428572, 133.42909090909092, 'X[9] <= 0.61\\ngini = 0.611\\nsamples = 6\\nvalue = [0, 1, 3, 2, 0, 0]'),\n",
              " Text(293.8040816326531, 123.54545454545455, 'X[6] <= 109.5\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 0, 2, 0, 0]'),\n",
              " Text(292.665306122449, 113.66181818181819, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(294.9428571428572, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(296.08163265306126, 123.54545454545455, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0]'),\n",
              " Text(280.20994897959184, 163.07999999999998, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0]'),\n",
              " Text(281.3487244897959, 172.96363636363637, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 0, 13, 0, 0]'),\n",
              " Text(319.71122448979594, 182.84727272727272, 'X[0] <= 9.95\\ngini = 0.613\\nsamples = 108\\nvalue = [0, 1, 5, 45, 49, 8]'),\n",
              " Text(309.7469387755102, 172.96363636363637, 'X[5] <= 13.5\\ngini = 0.583\\nsamples = 68\\nvalue = [0, 1, 2, 23, 37, 5]'),\n",
              " Text(302.3448979591837, 163.07999999999998, 'X[1] <= 0.415\\ngini = 0.539\\nsamples = 42\\nvalue = [0, 1, 2, 8, 27, 4]'),\n",
              " Text(299.4979591836735, 153.19636363636363, 'X[4] <= 0.098\\ngini = 0.335\\nsamples = 31\\nvalue = [0, 1, 0, 3, 25, 2]'),\n",
              " Text(298.35918367346943, 143.31272727272727, 'X[6] <= 7.5\\ngini = 0.25\\nsamples = 29\\nvalue = [0, 1, 0, 1, 25, 2]'),\n",
              " Text(297.22040816326535, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(299.4979591836735, 133.42909090909092, 'X[4] <= 0.051\\ngini = 0.196\\nsamples = 28\\nvalue = [0, 1, 0, 0, 25, 2]'),\n",
              " Text(298.35918367346943, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0, 0]'),\n",
              " Text(300.6367346938776, 123.54545454545455, 'X[2] <= 0.545\\ngini = 0.137\\nsamples = 27\\nvalue = [0, 0, 0, 0, 25, 2]'),\n",
              " Text(299.4979591836735, 113.66181818181819, 'X[1] <= 0.39\\ngini = 0.074\\nsamples = 26\\nvalue = [0, 0, 0, 0, 25, 1]'),\n",
              " Text(298.35918367346943, 103.77818181818182, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 0, 0, 0, 22, 0]'),\n",
              " Text(300.6367346938776, 103.77818181818182, 'X[7] <= 0.995\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 0, 0, 3, 1]'),\n",
              " Text(299.4979591836735, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(301.7755102040817, 93.89454545454547, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0]'),\n",
              " Text(301.7755102040817, 113.66181818181819, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(300.6367346938776, 143.31272727272727, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(305.1918367346939, 153.19636363636363, 'X[9] <= 0.635\\ngini = 0.694\\nsamples = 11\\nvalue = [0, 0, 2, 5, 2, 2]'),\n",
              " Text(302.91428571428577, 143.31272727272727, 'X[4] <= 0.095\\ngini = 0.5\\nsamples = 4\\nvalue = [0, 0, 2, 0, 2, 0]'),\n",
              " Text(301.7755102040817, 133.42909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2, 0, 0, 0]'),\n",
              " Text(304.05306122448985, 133.42909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 2, 0]'),\n",
              " Text(307.46938775510205, 143.31272727272727, 'X[2] <= 0.42\\ngini = 0.408\\nsamples = 7\\nvalue = [0, 0, 0, 5, 0, 2]'),\n",
              " Text(306.33061224489796, 133.42909090909092, 'X[5] <= 10.0\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 0, 0, 1, 0, 2]'),\n",
              " Text(305.1918367346939, 123.54545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 0, 2]'),\n",
              " Text(307.46938775510205, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0, 0]'),\n",
              " Text(308.60816326530613, 133.42909090909092, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 4, 0, 0]'),\n",
              " Text(317.1489795918368, 163.07999999999998, 'X[3] <= 3.15\\ngini = 0.518\\nsamples = 26\\nvalue = [0, 0, 0, 15, 10, 1]'),\n",
              " Text(314.30204081632655, 153.19636363636363, 'X[4] <= 0.073\\ngini = 0.375\\nsamples = 20\\nvalue = [0, 0, 0, 15, 5, 0]'),\n",
              " Text(312.0244897959184, 143.31272727272727, 'X[4] <= 0.048\\ngini = 0.142\\nsamples = 13\\nvalue = [0, 0, 0, 12, 1, 0]'),\n",
              " Text(310.8857142857143, 133.42909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(313.16326530612247, 133.42909090909092, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 0, 12, 0, 0]'),\n",
              " Text(316.5795918367347, 143.31272727272727, 'X[3] <= 2.7\\ngini = 0.49\\nsamples = 7\\nvalue = [0, 0, 0, 3, 4, 0]'),\n",
              " Text(315.44081632653064, 133.42909090909092, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 0, 4, 0]'),\n",
              " Text(317.7183673469388, 133.42909090909092, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3, 0, 0]'),\n",
              " Text(319.995918367347, 153.19636363636363, 'X[10] <= 12.7\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 0, 0, 0, 5, 1]'),\n",
              " Text(318.8571428571429, 143.31272727272727, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 0, 5, 0]'),\n",
              " Text(321.13469387755106, 143.31272727272727, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(329.67551020408166, 172.96363636363637, 'X[2] <= 0.7\\ngini = 0.596\\nsamples = 40\\nvalue = [0, 0, 3, 22, 12, 3]'),\n",
              " Text(326.8285714285715, 163.07999999999998, 'X[10] <= 12.3\\ngini = 0.554\\nsamples = 36\\nvalue = [0, 0, 2, 22, 9, 3]'),\n",
              " Text(324.5510204081633, 153.19636363636363, 'X[10] <= 12.05\\ngini = 0.592\\nsamples = 25\\nvalue = [0, 0, 2, 13, 9, 1]'),\n",
              " Text(323.4122448979592, 143.31272727272727, 'X[1] <= 0.275\\ngini = 0.566\\nsamples = 22\\nvalue = [0, 0, 2, 13, 6, 1]'),\n",
              " Text(321.13469387755106, 133.42909090909092, 'X[6] <= 49.5\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 0, 0, 1]'),\n",
              " Text(319.995918367347, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(322.27346938775514, 123.54545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 1]'),\n",
              " Text(325.6897959183674, 133.42909090909092, 'X[3] <= 2.3\\ngini = 0.485\\nsamples = 20\\nvalue = [0, 0, 1, 13, 6, 0]'),\n",
              " Text(324.5510204081633, 123.54545454545455, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 0, 6, 0, 0]'),\n",
              " Text(326.8285714285715, 123.54545454545455, 'X[7] <= 0.998\\ngini = 0.561\\nsamples = 14\\nvalue = [0, 0, 1, 7, 6, 0]'),\n",
              " Text(324.5510204081633, 113.66181818181819, 'X[1] <= 0.39\\ngini = 0.408\\nsamples = 7\\nvalue = [0, 0, 0, 2, 5, 0]'),\n",
              " Text(323.4122448979592, 103.77818181818182, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0, 0]'),\n",
              " Text(325.6897959183674, 103.77818181818182, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 0, 5, 0]'),\n",
              " Text(329.10612244897965, 113.66181818181819, 'X[6] <= 13.5\\ngini = 0.449\\nsamples = 7\\nvalue = [0, 0, 1, 5, 1, 0]'),\n",
              " Text(327.96734693877556, 103.77818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]'),\n",
              " Text(330.24489795918373, 103.77818181818182, 'X[1] <= 0.385\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 0, 0, 5, 1, 0]'),\n",
              " Text(329.10612244897965, 93.89454545454547, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0]'),\n",
              " Text(331.38367346938776, 93.89454545454547, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 5, 0, 0]'),\n",
              " Text(325.6897959183674, 143.31272727272727, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0]'),\n",
              " Text(329.10612244897965, 153.19636363636363, 'X[6] <= 21.5\\ngini = 0.298\\nsamples = 11\\nvalue = [0, 0, 0, 9, 0, 2]'),\n",
              " Text(327.96734693877556, 143.31272727272727, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 0, 0, 2]'),\n",
              " Text(330.24489795918373, 143.31272727272727, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 0, 9, 0, 0]'),\n",
              " Text(332.52244897959184, 163.07999999999998, 'X[6] <= 76.5\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 1, 0, 3, 0]'),\n",
              " Text(331.38367346938776, 153.19636363636363, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0]'),\n",
              " Text(333.6612244897959, 153.19636363636363, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0, 0]')]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# see the tree\n",
        "from sklearn import tree\n",
        "tree.plot_tree(dt_clf.fit(X_train, y_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kyTpdVAdUhK"
      },
      "outputs": [],
      "source": [
        "# Model has learnt everything that is nothing but overfitting\n",
        "# we need to optimize\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydGckipfddZT",
        "outputId": "47a24eaf-6b79-492e-d1f7-90aa86754dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_train, y_pred_train_dt),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdAiV6mLdhcJ",
        "outputId": "16c44e4a-a67a-4c11-baa5-3262a284dcec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_test, y_pred_test_dt),2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2wI7czwdyN0"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "path = dt_clf.cost_complexity_pruning_path(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3QJvZ-8d9_F",
        "outputId": "1468dfbe-b7e4-4622-de81-91b758811dd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.00058088, 0.00058309, 0.00074471, 0.00077179,\n",
              "       0.00080429, 0.00081918, 0.00082216, 0.00082491, 0.00082491,\n",
              "       0.00082491, 0.00082982, 0.0008378 , 0.00085041, 0.00085216,\n",
              "       0.00085928, 0.00085928, 0.00087303, 0.00089366, 0.00089366,\n",
              "       0.00089366, 0.00089366, 0.00089366, 0.00089366, 0.00089366,\n",
              "       0.00089366, 0.00089366, 0.00089366, 0.00089366, 0.00089366,\n",
              "       0.00089366, 0.00089366, 0.00103612, 0.00110492, 0.0011543 ,\n",
              "       0.00116175, 0.00119154, 0.00119154, 0.00119154, 0.00119154,\n",
              "       0.00119154, 0.00119154, 0.00119154, 0.00119154, 0.00119154,\n",
              "       0.00119154, 0.00119154, 0.00119154, 0.00119154, 0.00119154,\n",
              "       0.00130738, 0.00132393, 0.00134048, 0.00134048, 0.00134048,\n",
              "       0.00134048, 0.00134048, 0.00134048, 0.00134048, 0.00134048,\n",
              "       0.00134048, 0.00134048, 0.00134048, 0.00134048, 0.00134048,\n",
              "       0.00134048, 0.00136176, 0.00136176, 0.0013811 , 0.00139634,\n",
              "       0.00140432, 0.00141977, 0.00142985, 0.00142985, 0.00142985,\n",
              "       0.00142985, 0.0014412 , 0.00145219, 0.00145219, 0.0014546 ,\n",
              "       0.00146017, 0.00148943, 0.00148943, 0.00148943, 0.00148943,\n",
              "       0.00153198, 0.00153624, 0.00154544, 0.0015639 , 0.0015639 ,\n",
              "       0.00156525, 0.0015693 , 0.00158424, 0.00158741, 0.00158796,\n",
              "       0.00158872, 0.00158872, 0.00160858, 0.00160858, 0.00160858,\n",
              "       0.00160858, 0.00160858, 0.00160858, 0.00161975, 0.00163018,\n",
              "       0.00163701, 0.00163837, 0.00163837, 0.00164982, 0.00166816,\n",
              "       0.00168802, 0.00168878, 0.00170167, 0.00173766, 0.00174218,\n",
              "       0.00174263, 0.00178731, 0.00178731, 0.0018171 , 0.0018171 ,\n",
              "       0.00185695, 0.00186923, 0.00190088, 0.00191774, 0.00194618,\n",
              "       0.00199583, 0.00207872, 0.0020852 , 0.0020852 , 0.00209512,\n",
              "       0.00209603, 0.0021145 , 0.00214477, 0.00214649, 0.00216539,\n",
              "       0.00217456, 0.00221727, 0.00224277, 0.00224903, 0.00226906,\n",
              "       0.00229349, 0.00233281, 0.00233569, 0.00238308, 0.00239301,\n",
              "       0.00243904, 0.00248238, 0.00248366, 0.00249674, 0.00250223,\n",
              "       0.00251784, 0.00252629, 0.00259663, 0.00260649, 0.00263972,\n",
              "       0.00268249, 0.00269364, 0.0027095 , 0.00275389, 0.00275544,\n",
              "       0.00281119, 0.00286376, 0.00299374, 0.00301857, 0.00306348,\n",
              "       0.00312779, 0.00320841, 0.00331025, 0.00338361, 0.00339294,\n",
              "       0.00370056, 0.00383892, 0.00385893, 0.00400584, 0.00403601,\n",
              "       0.0040543 , 0.00415053, 0.0041823 , 0.0044017 , 0.00500447,\n",
              "       0.0054185 , 0.00651323, 0.00655364, 0.0070582 , 0.01033366,\n",
              "       0.01251074, 0.06471415])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "alphas = path['ccp_alphas']\n",
        "alphas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fL55m_NeBeR"
      },
      "outputs": [],
      "source": [
        "accuracy_train, accuracy_test = [],[]\n",
        "\n",
        "for i in alphas:\n",
        "    dt_clf = DecisionTreeClassifier(ccp_alpha=i)    \n",
        "    \n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    y_pred_train1 = dt_clf.predict(X_train)\n",
        "    y_pred_test1 = dt_clf.predict(X_test)\n",
        "    \n",
        "    accuracy_train.append(accuracy_score(y_train, y_pred_train1))\n",
        "    accuracy_test.append(accuracy_score(y_test,y_pred_test1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq4E2_1-eHRh",
        "outputId": "c96fd89c-c5ab-471e-97f0-727b3a48e7e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.9991063449508489,\n",
              " 0.998212689901698,\n",
              " 0.9973190348525469,\n",
              " 0.9955317247542449,\n",
              " 0.9946380697050938,\n",
              " 0.9937444146559428,\n",
              " 0.9919571045576407,\n",
              " 0.9892761394101877,\n",
              " 0.9892761394101877,\n",
              " 0.9892761394101877,\n",
              " 0.9883824843610366,\n",
              " 0.9874888293118856,\n",
              " 0.9857015192135835,\n",
              " 0.9848078641644326,\n",
              " 0.9830205540661304,\n",
              " 0.9830205540661304,\n",
              " 0.9821268990169795,\n",
              " 0.968722073279714,\n",
              " 0.968722073279714,\n",
              " 0.968722073279714,\n",
              " 0.9696157283288651,\n",
              " 0.968722073279714,\n",
              " 0.9696157283288651,\n",
              " 0.968722073279714,\n",
              " 0.968722073279714,\n",
              " 0.968722073279714,\n",
              " 0.9696157283288651,\n",
              " 0.968722073279714,\n",
              " 0.968722073279714,\n",
              " 0.968722073279714,\n",
              " 0.967828418230563,\n",
              " 0.9651474530831099,\n",
              " 0.9651474530831099,\n",
              " 0.9615728328865059,\n",
              " 0.9606791778373548,\n",
              " 0.9490616621983914,\n",
              " 0.9490616621983914,\n",
              " 0.9463806970509383,\n",
              " 0.9463806970509383,\n",
              " 0.9490616621983914,\n",
              " 0.9454870420017873,\n",
              " 0.9463806970509383,\n",
              " 0.9463806970509383,\n",
              " 0.9463806970509383,\n",
              " 0.9472743521000894,\n",
              " 0.9481680071492404,\n",
              " 0.9472743521000894,\n",
              " 0.9472743521000894,\n",
              " 0.9490616621983914,\n",
              " 0.9436997319034852,\n",
              " 0.9419124218051832,\n",
              " 0.9302949061662198,\n",
              " 0.9294012511170688,\n",
              " 0.9294012511170688,\n",
              " 0.9294012511170688,\n",
              " 0.9302949061662198,\n",
              " 0.9302949061662198,\n",
              " 0.9294012511170688,\n",
              " 0.9285075960679178,\n",
              " 0.9285075960679178,\n",
              " 0.9276139410187667,\n",
              " 0.9320822162645219,\n",
              " 0.9285075960679178,\n",
              " 0.9285075960679178,\n",
              " 0.9294012511170688,\n",
              " 0.9249329758713136,\n",
              " 0.9267202859696158,\n",
              " 0.9267202859696158,\n",
              " 0.9249329758713136,\n",
              " 0.9231456657730116,\n",
              " 0.9195710455764075,\n",
              " 0.9142091152815014,\n",
              " 0.9151027703306523,\n",
              " 0.9142091152815014,\n",
              " 0.9151027703306523,\n",
              " 0.9106344950848972,\n",
              " 0.9106344950848972,\n",
              " 0.9052725647899911,\n",
              " 0.9052725647899911,\n",
              " 0.9088471849865952,\n",
              " 0.9070598748882931,\n",
              " 0.903485254691689,\n",
              " 0.8990169794459338,\n",
              " 0.8981233243967829,\n",
              " 0.8981233243967829,\n",
              " 0.8972296693476318,\n",
              " 0.8945487042001787,\n",
              " 0.8918677390527256,\n",
              " 0.8927613941018767,\n",
              " 0.8909740840035746,\n",
              " 0.8900804289544236,\n",
              " 0.8873994638069705,\n",
              " 0.8856121537086684,\n",
              " 0.8856121537086684,\n",
              " 0.8820375335120644,\n",
              " 0.8793565683646113,\n",
              " 0.8775692582663092,\n",
              " 0.8748882931188561,\n",
              " 0.872207327971403,\n",
              " 0.8748882931188561,\n",
              " 0.8748882931188561,\n",
              " 0.872207327971403,\n",
              " 0.8739946380697051,\n",
              " 0.872207327971403,\n",
              " 0.8668453976764968,\n",
              " 0.8677390527256479,\n",
              " 0.8641644325290437,\n",
              " 0.8632707774798928,\n",
              " 0.8623771224307417,\n",
              " 0.8605898123324397,\n",
              " 0.8605898123324397,\n",
              " 0.8596961572832886,\n",
              " 0.8588025022341377,\n",
              " 0.8605898123324397,\n",
              " 0.8561215370866846,\n",
              " 0.8507596067917784,\n",
              " 0.8525469168900804,\n",
              " 0.8489722966934763,\n",
              " 0.8507596067917784,\n",
              " 0.8453976764968723,\n",
              " 0.8445040214477212,\n",
              " 0.840929401251117,\n",
              " 0.8418230563002681,\n",
              " 0.8400357462019661,\n",
              " 0.8364611260053619,\n",
              " 0.8302055406613047,\n",
              " 0.8266309204647007,\n",
              " 0.8284182305630027,\n",
              " 0.8266309204647007,\n",
              " 0.8239499553172476,\n",
              " 0.8132260947274352,\n",
              " 0.8159070598748883,\n",
              " 0.8132260947274352,\n",
              " 0.8123324396782842,\n",
              " 0.803395889186774,\n",
              " 0.7998212689901698,\n",
              " 0.7971403038427167,\n",
              " 0.7998212689901698,\n",
              " 0.7864164432529044,\n",
              " 0.7917783735478106,\n",
              " 0.7765862377122431,\n",
              " 0.7801608579088471,\n",
              " 0.7783735478105451,\n",
              " 0.7712243074173369,\n",
              " 0.775692582663092,\n",
              " 0.773011617515639,\n",
              " 0.7712243074173369,\n",
              " 0.7587131367292225,\n",
              " 0.7613941018766756,\n",
              " 0.7515638963360143,\n",
              " 0.7479892761394102,\n",
              " 0.7426273458445041,\n",
              " 0.7408400357462019,\n",
              " 0.7390527256478999,\n",
              " 0.7301161751563896,\n",
              " 0.7301161751563896,\n",
              " 0.7256478999106345,\n",
              " 0.7131367292225201,\n",
              " 0.711349419124218,\n",
              " 0.709562109025916,\n",
              " 0.7068811438784629,\n",
              " 0.7050938337801609,\n",
              " 0.7006255585344057,\n",
              " 0.6934763181411975,\n",
              " 0.6890080428954424,\n",
              " 0.6854334226988382,\n",
              " 0.6791778373547811,\n",
              " 0.6586237712243074,\n",
              " 0.6559428060768543,\n",
              " 0.6550491510277033,\n",
              " 0.6496872207327972,\n",
              " 0.6470062555853441,\n",
              " 0.6470062555853441,\n",
              " 0.6434316353887399,\n",
              " 0.6255585344057194,\n",
              " 0.6255585344057194,\n",
              " 0.6210902591599643,\n",
              " 0.6210902591599643,\n",
              " 0.6112600536193029,\n",
              " 0.6076854334226989,\n",
              " 0.6014298480786416,\n",
              " 0.5933869526362824,\n",
              " 0.5933869526362824,\n",
              " 0.5933869526362824,\n",
              " 0.5781948168007149,\n",
              " 0.4486148346738159]"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6ZtlQBOe3-V",
        "outputId": "6077e4c3-7e90-4349-9477-0c2b1f6155a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.6083333333333333,\n",
              " 0.575,\n",
              " 0.6020833333333333,\n",
              " 0.5895833333333333,\n",
              " 0.6,\n",
              " 0.5854166666666667,\n",
              " 0.5875,\n",
              " 0.59375,\n",
              " 0.5979166666666667,\n",
              " 0.6,\n",
              " 0.59375,\n",
              " 0.6083333333333333,\n",
              " 0.6020833333333333,\n",
              " 0.5833333333333334,\n",
              " 0.6,\n",
              " 0.5979166666666667,\n",
              " 0.6104166666666667,\n",
              " 0.5958333333333333,\n",
              " 0.5875,\n",
              " 0.58125,\n",
              " 0.6083333333333333,\n",
              " 0.5895833333333333,\n",
              " 0.5916666666666667,\n",
              " 0.59375,\n",
              " 0.6125,\n",
              " 0.6041666666666666,\n",
              " 0.6,\n",
              " 0.6083333333333333,\n",
              " 0.5729166666666666,\n",
              " 0.5875,\n",
              " 0.6041666666666666,\n",
              " 0.5958333333333333,\n",
              " 0.5979166666666667,\n",
              " 0.6041666666666666,\n",
              " 0.5979166666666667,\n",
              " 0.59375,\n",
              " 0.5833333333333334,\n",
              " 0.5958333333333333,\n",
              " 0.6,\n",
              " 0.5958333333333333,\n",
              " 0.59375,\n",
              " 0.58125,\n",
              " 0.60625,\n",
              " 0.60625,\n",
              " 0.5895833333333333,\n",
              " 0.59375,\n",
              " 0.6,\n",
              " 0.5916666666666667,\n",
              " 0.59375,\n",
              " 0.5729166666666666,\n",
              " 0.5708333333333333,\n",
              " 0.5791666666666667,\n",
              " 0.6,\n",
              " 0.58125,\n",
              " 0.5854166666666667,\n",
              " 0.5770833333333333,\n",
              " 0.5791666666666667,\n",
              " 0.5666666666666667,\n",
              " 0.5916666666666667,\n",
              " 0.5916666666666667,\n",
              " 0.5895833333333333,\n",
              " 0.59375,\n",
              " 0.5833333333333334,\n",
              " 0.5875,\n",
              " 0.5833333333333334,\n",
              " 0.5833333333333334,\n",
              " 0.5895833333333333,\n",
              " 0.5833333333333334,\n",
              " 0.5645833333333333,\n",
              " 0.5770833333333333,\n",
              " 0.59375,\n",
              " 0.5875,\n",
              " 0.5895833333333333,\n",
              " 0.5958333333333333,\n",
              " 0.5875,\n",
              " 0.5833333333333334,\n",
              " 0.6,\n",
              " 0.5916666666666667,\n",
              " 0.5979166666666667,\n",
              " 0.5875,\n",
              " 0.58125,\n",
              " 0.58125,\n",
              " 0.5875,\n",
              " 0.5979166666666667,\n",
              " 0.575,\n",
              " 0.59375,\n",
              " 0.5875,\n",
              " 0.5833333333333334,\n",
              " 0.5895833333333333,\n",
              " 0.6,\n",
              " 0.59375,\n",
              " 0.5875,\n",
              " 0.5916666666666667,\n",
              " 0.59375,\n",
              " 0.5979166666666667,\n",
              " 0.5895833333333333,\n",
              " 0.5833333333333334,\n",
              " 0.6,\n",
              " 0.5958333333333333,\n",
              " 0.5895833333333333,\n",
              " 0.5958333333333333,\n",
              " 0.5979166666666667,\n",
              " 0.59375,\n",
              " 0.5916666666666667,\n",
              " 0.59375,\n",
              " 0.6020833333333333,\n",
              " 0.5875,\n",
              " 0.6041666666666666,\n",
              " 0.5958333333333333,\n",
              " 0.5958333333333333,\n",
              " 0.6020833333333333,\n",
              " 0.5916666666666667,\n",
              " 0.5979166666666667,\n",
              " 0.6,\n",
              " 0.5916666666666667,\n",
              " 0.6020833333333333,\n",
              " 0.6020833333333333,\n",
              " 0.6041666666666666,\n",
              " 0.5958333333333333,\n",
              " 0.6145833333333334,\n",
              " 0.61875,\n",
              " 0.6104166666666667,\n",
              " 0.60625,\n",
              " 0.6020833333333333,\n",
              " 0.6145833333333334,\n",
              " 0.6041666666666666,\n",
              " 0.60625,\n",
              " 0.6,\n",
              " 0.5916666666666667,\n",
              " 0.6,\n",
              " 0.5916666666666667,\n",
              " 0.5895833333333333,\n",
              " 0.5875,\n",
              " 0.5854166666666667,\n",
              " 0.5833333333333334,\n",
              " 0.5875,\n",
              " 0.58125,\n",
              " 0.58125,\n",
              " 0.5791666666666667,\n",
              " 0.58125,\n",
              " 0.5729166666666666,\n",
              " 0.5708333333333333,\n",
              " 0.5625,\n",
              " 0.5645833333333333,\n",
              " 0.5666666666666667,\n",
              " 0.55625,\n",
              " 0.5645833333333333,\n",
              " 0.5604166666666667,\n",
              " 0.5625,\n",
              " 0.56875,\n",
              " 0.5729166666666666,\n",
              " 0.5708333333333333,\n",
              " 0.56875,\n",
              " 0.5645833333333333,\n",
              " 0.5625,\n",
              " 0.5666666666666667,\n",
              " 0.5666666666666667,\n",
              " 0.5625,\n",
              " 0.5625,\n",
              " 0.5645833333333333,\n",
              " 0.5729166666666666,\n",
              " 0.5729166666666666,\n",
              " 0.5729166666666666,\n",
              " 0.5729166666666666,\n",
              " 0.5729166666666666,\n",
              " 0.5708333333333333,\n",
              " 0.575,\n",
              " 0.575,\n",
              " 0.5708333333333333,\n",
              " 0.5708333333333333,\n",
              " 0.575,\n",
              " 0.58125,\n",
              " 0.5875,\n",
              " 0.5875,\n",
              " 0.5875,\n",
              " 0.5729166666666666,\n",
              " 0.5729166666666666,\n",
              " 0.5625,\n",
              " 0.5625,\n",
              " 0.5729166666666666,\n",
              " 0.55625,\n",
              " 0.5354166666666667,\n",
              " 0.53125,\n",
              " 0.53125,\n",
              " 0.53125,\n",
              " 0.5208333333333334,\n",
              " 0.3729166666666667]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "bkRDfHA3e6wI",
        "outputId": "5a5c8cbb-240c-4d25-e6ee-6372cb270e87"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# now we have scores\n",
        "# lets, plot\n",
        "\n",
        "sns.set()\n",
        "plt.figure(figsize = (16,8))\n",
        "sns.lineplot(y =accuracy_train, x = alphas, label = 'TrainAccuracy')\n",
        "sns.lineplot(y =accuracy_test, x = alphas, label = 'TestAccuracy')\n",
        "plt.xticks(ticks=np.arange(0.00,0.15,0.01))\n",
        "plt.xlabel('alphas')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAQoo1orfAnO"
      },
      "outputs": [],
      "source": [
        "#_________with ccp = 0.01\n",
        "dt_clf = DecisionTreeClassifier(ccp_alpha=0.01, random_state = 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OxMjPgsfJiE",
        "outputId": "9836c72d-e830-42e5-be03-988a1b19235f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.01, random_state=14)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt_clf.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu9SXG_7fPy7"
      },
      "outputs": [],
      "source": [
        "y_pred_train2 = dt_clf.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih_OEJkFfUc1"
      },
      "outputs": [],
      "source": [
        "y_pred_test2 = dt_clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqn_brMwffA9",
        "outputId": "1f839762-a809-4b0a-cadf-f7217d14483f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.59\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(round(accuracy_score(y_train,y_pred_train2), 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C1jY0Kifh5x",
        "outputId": "ce0a4f8a-1d63-41f8-a017-5bb07ac7c965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.53\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_test,y_pred_test2), 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euByNMzgfkYP"
      },
      "outputs": [],
      "source": [
        "#Earlier before optimization accuracys were 1 and 0.6 (train & test)\n",
        "#Now after optimization accuracys are 0.59 and 0.53 (train & test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWqGzy3hgfu9",
        "outputId": "9ba1e1b0-f2cd-4a1a-bec2-2846a5d52f45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   3   1   0   0]\n",
            " [  0   0  10   8   0   0]\n",
            " [  0   0 129  50   0   0]\n",
            " [  0   0  82 126   0   0]\n",
            " [  0   0   3  64   0   0]\n",
            " [  0   0   0   4   0   0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred_test2)\n",
        "print(confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3isq33LggKr",
        "outputId": "f9b08b45-8c02-4be9-a103-33f0ffdda3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.57      0.72      0.64       179\n",
            "           4       0.50      0.61      0.55       208\n",
            "           5       0.00      0.00      0.00        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.53       480\n",
            "   macro avg       0.18      0.22      0.20       480\n",
            "weighted avg       0.43      0.53      0.47       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_test2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBWnL0lrg_A3"
      },
      "source": [
        "**#Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfVYJw_Ig56-"
      },
      "outputs": [],
      "source": [
        "#import the classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PegAI0ZIhG-G"
      },
      "outputs": [],
      "source": [
        "#in our previous experiment, we found ccp_alphas = 0.013 has the best accuarcy \n",
        "rf_clf = RandomForestClassifier(n_estimators =100, ccp_alpha= 0.01, random_state = 14)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a79BEyFuhLqx",
        "outputId": "e0d73691-149e-4314-cd68-b8743082a9ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#fit the classifier with x and y  data = train\n",
        "rf_mod = rf_clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya_A3BgGhRb1",
        "outputId": "be8ed909-412c-4f3d-9c66-3cd4306556b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 4])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prediction \n",
        "y_train_pred_rf1 = rf_mod.predict(X_train)\n",
        "y_train_pred_rf1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8TI5C1zhVOO",
        "outputId": "b4613bb4-20a1-48ee-9b82-a5082c497d81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 4, 3,\n",
              "       3, 4, 3, 4, 3, 3, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4,\n",
              "       3, 4, 4, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 3, 4,\n",
              "       3, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 4, 3, 4, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       4, 4, 3, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 3,\n",
              "       3, 3, 4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 4, 3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3,\n",
              "       4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 3, 3,\n",
              "       3, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 3,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prediction \n",
        "y_test_pred_rf1 = rf_mod.predict(X_test)\n",
        "y_test_pred_rf1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOnl8gJvheyn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T97jsBzhhFW",
        "outputId": "353fc63b-07f8-4411-d055-9ca3682fdcf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.62\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_train,y_train_pred_rf1), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuF8TMMhh7Xy",
        "outputId": "89272e27-33d0-4b6e-f686-8d1a328b62d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.55\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_test,y_test_pred_rf1), 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_Rhbr6kh9qH"
      },
      "outputs": [],
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r__Iqy_JiA1A",
        "outputId": "94fa4a1f-0a86-4ecb-b15f-c6faf385b1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   3   1   0   0]\n",
            " [  0   0  13   5   0   0]\n",
            " [  0   0 139  40   0   0]\n",
            " [  0   0  85 123   0   0]\n",
            " [  0   0   3  64   0   0]\n",
            " [  0   0   0   4   0   0]]\n"
          ]
        }
      ],
      "source": [
        "confusion_matrix = confusion_matrix(y_test, y_test_pred_rf1)\n",
        "print(confusion_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk1lYoTfiDX6"
      },
      "outputs": [],
      "source": [
        "### Classification Report\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY3lxfgtiHeq",
        "outputId": "5e3b7403-224a-45d5-9059-7b8320215344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.57      0.78      0.66       179\n",
            "           4       0.52      0.59      0.55       208\n",
            "           5       0.00      0.00      0.00        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.55       480\n",
            "   macro avg       0.18      0.23      0.20       480\n",
            "weighted avg       0.44      0.55      0.49       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_test_pred_rf1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BgvPuPDiJuT"
      },
      "outputs": [],
      "source": [
        "#_____________________________ Extract Feature Importance \n",
        "fi = pd.DataFrame({'feature': list(X_train.columns),\n",
        "                   'importance': rf_mod.feature_importances_}).\\\n",
        "    sort_values('importance', ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K0bgKBfDjfgQ",
        "outputId": "73bdfa01-371a-473c-a643-74b73456893f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>alcohol</td>\n",
              "      <td>0.448663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>volatile_acidity</td>\n",
              "      <td>0.150800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>total_sulfur_dioxide</td>\n",
              "      <td>0.116731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sulphates</td>\n",
              "      <td>0.113725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>density</td>\n",
              "      <td>0.070888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 feature  importance\n",
              "10               alcohol    0.448663\n",
              "1       volatile_acidity    0.150800\n",
              "6   total_sulfur_dioxide    0.116731\n",
              "9              sulphates    0.113725\n",
              "7                density    0.070888"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fi.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EShIRWuWk_9s"
      },
      "outputs": [],
      "source": [
        "# Accuarcy above is 0.62 & 0.55 for Train & test (respectively)\n",
        "# This accuracy is for having all columns as features in our model\n",
        "# Lets build a model keeping 4 best features \n",
        "# that is keeping volatile_acidity, total_sulfur_dioxide, sulphates, alcohol only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th2bDjjzl5x7"
      },
      "outputs": [],
      "source": [
        "#Create Classifier object \n",
        "#in our previous experiment Decision Tree model, \n",
        "#we found ccp_alphas = 0.01 has the best accuarcy \n",
        "clf_rf1 = RandomForestClassifier(n_estimators =100, ccp_alpha= 0.01, random_state = 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ngExeImHGt",
        "outputId": "18359186-9b22-47ad-a0b6-895a6021399f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1119 entries, 318 to 619\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed_acidity         1119 non-null   float64\n",
            " 1   volatile_acidity      1119 non-null   float64\n",
            " 2   citric_acid           1119 non-null   float64\n",
            " 3   residual_sugar        1119 non-null   float64\n",
            " 4   chlorides             1119 non-null   float64\n",
            " 5   free_sulfur_dioxide   1119 non-null   float64\n",
            " 6   total_sulfur_dioxide  1119 non-null   float64\n",
            " 7   density               1119 non-null   float64\n",
            " 8   pH                    1119 non-null   float64\n",
            " 9   sulphates             1119 non-null   float64\n",
            " 10  alcohol               1119 non-null   float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 104.9 KB\n"
          ]
        }
      ],
      "source": [
        "# fit the classifier with x and y data=TRAIN, \n",
        "#this time with Failure_Type only\n",
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASSjGoaqmLFY",
        "outputId": "7599af7a-4fa3-4f96-9708-fb019d31e307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1119 entries, 318 to 619\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   volatile_acidity      1119 non-null   float64\n",
            " 1   total_sulfur_dioxide  1119 non-null   float64\n",
            " 2   sulphates             1119 non-null   float64\n",
            " 3   alcohol               1119 non-null   float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 43.7 KB\n"
          ]
        }
      ],
      "source": [
        "X_train1 = X_train.iloc[ : ,[1,6,9,10]]\n",
        "X_train1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhHtEMamf6N",
        "outputId": "04b65c4b-3824-4e71-e229-cfeff5f1a021"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "rf_mod1 = clf_rf1.fit(X_train1, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roqk3_RFmi0N",
        "outputId": "4857c788-2984-4a4e-f381-ac5b578fab30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 3])"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prediction \n",
        "y_train_pred1 = rf_mod1.predict(X_train1)\n",
        "y_train_pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcNky1klnbq5",
        "outputId": "1306b63b-ea67-4fc8-ae3d-ddaa673f78c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 480 entries, 667 to 1589\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed_acidity         480 non-null    float64\n",
            " 1   volatile_acidity      480 non-null    float64\n",
            " 2   citric_acid           480 non-null    float64\n",
            " 3   residual_sugar        480 non-null    float64\n",
            " 4   chlorides             480 non-null    float64\n",
            " 5   free_sulfur_dioxide   480 non-null    float64\n",
            " 6   total_sulfur_dioxide  480 non-null    float64\n",
            " 7   density               480 non-null    float64\n",
            " 8   pH                    480 non-null    float64\n",
            " 9   sulphates             480 non-null    float64\n",
            " 10  alcohol               480 non-null    float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 45.0 KB\n"
          ]
        }
      ],
      "source": [
        "X_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp_yYGiGng6I",
        "outputId": "7f52e4bf-1c2c-4ef6-9b7a-cb470db65227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 480 entries, 667 to 1589\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   volatile_acidity      480 non-null    float64\n",
            " 1   total_sulfur_dioxide  480 non-null    float64\n",
            " 2   sulphates             480 non-null    float64\n",
            " 3   alcohol               480 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 18.8 KB\n"
          ]
        }
      ],
      "source": [
        "X_test1 = X_test.iloc[ : ,[1,6,9,10]]\n",
        "X_test1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e6oRx1Inmk_",
        "outputId": "28f4fd05-50b3-4f05-bf32-d44264f874c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 3, 4, 4, 4, 4, 3, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 3, 4, 4, 3, 4, 3, 4, 3,\n",
              "       3, 3, 3, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3,\n",
              "       4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3, 4, 3, 3, 3, 3, 4,\n",
              "       3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 3, 4,\n",
              "       3, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 4, 3, 4, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4,\n",
              "       4, 4, 3, 4, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 3,\n",
              "       3, 3, 4, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3,\n",
              "       4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3,\n",
              "       3, 3, 4, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 3,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 3, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 3, 3])"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prediction \n",
        "y_test_pred1 = rf_mod1.predict(X_test1)\n",
        "y_test_pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTyZQkWjnt2L"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNwiX6ZNoau7",
        "outputId": "4a9b0b18-388b-416e-b035-39320b7f1c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.61\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_train,y_train_pred1), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IznaUoQJodpZ",
        "outputId": "4208743d-f99b-4a77-ee79-d9618780aaf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.53\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_test,y_test_pred1), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XImhP5k7ogdm"
      },
      "outputs": [],
      "source": [
        "### There is no much difference in accuarcy \n",
        "#Earlier train accuracy = 0.62 now with 4 features its 0.61\n",
        "#Earlier test accuracy = 0.55 now with 4 features its 0.53"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eArmkCO6qaDG"
      },
      "outputs": [],
      "source": [
        "### Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2_jJzNVqcIl",
        "outputId": "3225c9fc-52ca-4bda-ef3a-3867c1b451eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   3   1   0   0]\n",
            " [  0   0  13   5   0   0]\n",
            " [  0   0 135  44   0   0]\n",
            " [  0   0  89 119   0   0]\n",
            " [  0   0   2  65   0   0]\n",
            " [  0   0   0   4   0   0]]\n"
          ]
        }
      ],
      "source": [
        "confusion_matrix = confusion_matrix(y_test, y_test_pred1)\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Wx10UFrw3T",
        "outputId": "c516ee4f-1a19-4e10-d21f-8dead3101e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.56      0.75      0.64       179\n",
            "           4       0.50      0.57      0.53       208\n",
            "           5       0.00      0.00      0.00        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.53       480\n",
            "   macro avg       0.18      0.22      0.20       480\n",
            "weighted avg       0.42      0.53      0.47       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "### Classification Report\n",
        "print(classification_report(y_test, y_test_pred1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMewGLwFtylb"
      },
      "source": [
        "***### Ensemble Techniques***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVURofA0t640"
      },
      "source": [
        "# **Ada Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ItnYA5kr_RN"
      },
      "outputs": [],
      "source": [
        "# Importing algorithm\n",
        "from sklearn.ensemble import AdaBoostClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM3IWfdVvL-S"
      },
      "outputs": [],
      "source": [
        "ada= AdaBoostClassifier(n_estimators=100, learning_rate=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD6y_aynvkiE",
        "outputId": "22c3a670-a306-4579-da9f-c6f176336ef8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "mod_ada= ada.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbZIi-MMv1tp",
        "outputId": "d3aef4db-7a8f-4504-880d-3b2d1024fea6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 3, 3])"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' Predicting on train data '''\n",
        "y_pred_train_ada= mod_ada.predict(X_train)\n",
        "y_pred_train_ada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3i7WchZwWw_",
        "outputId": "edf8566c-dc66-4484-eb0b-92777f8ecc70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 4, 4, 4, 3,\n",
              "       4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3,\n",
              "       3, 3, 4, 4, 3, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4, 3, 4, 4,\n",
              "       4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 4, 3, 4, 4, 3, 4, 3, 4,\n",
              "       3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 3, 4, 3, 3, 4, 1, 3, 3, 4, 4, 3, 3,\n",
              "       3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 1, 4,\n",
              "       3, 4, 3, 3, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3,\n",
              "       4, 3, 3, 4, 3, 4, 3, 4, 3, 4, 3, 3, 4, 4, 3, 4, 3, 4, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4,\n",
              "       3, 4, 3, 4, 3, 3, 3, 4, 4, 3, 3, 4, 4, 4, 3, 3, 4, 4, 4, 3, 3, 3,\n",
              "       4, 4, 3, 4, 3, 3, 3, 3, 4, 1, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 3,\n",
              "       4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3,\n",
              "       3, 4, 4, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4,\n",
              "       4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 4, 3, 4, 3, 4, 4, 1, 4, 3, 3, 3, 4, 3, 3, 4, 4, 4, 3, 3,\n",
              "       3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 4, 1, 4, 3, 4, 4, 4, 4, 3, 3, 3, 3])"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' Predicting on test data '''\n",
        "y_pred_test_ada= mod_ada.predict(X_test)\n",
        "y_pred_test_ada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1VTu2ojw6I2",
        "outputId": "f06f8757-5030-4019-e5b7-70ab2d4ec574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.59\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(round(accuracy_score(y_train, y_pred_train_ada), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v9Je4IGxKBY",
        "outputId": "9130879c-9d04-42f2-89d8-556754a3f775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.52\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_test, y_pred_test_ada), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9soyQ119xQHP"
      },
      "outputs": [],
      "source": [
        "### Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSCIRqQqxXCg",
        "outputId": "51553e22-d082-4103-b8a1-6a5597404ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  1   0   3   0   0   0]\n",
            " [  1   0  11   6   0   0]\n",
            " [  3   0 126  50   0   0]\n",
            " [  1   0  85 122   0   0]\n",
            " [  0   0   5  62   0   0]\n",
            " [  0   0   0   4   0   0]]\n"
          ]
        }
      ],
      "source": [
        "confusion_matrix = confusion_matrix(y_test, y_pred_test_ada)\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szt72VP1xdfW",
        "outputId": "f37d8866-7638-455d-9b9c-f345e92bd87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.17      0.25      0.20         4\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.55      0.70      0.62       179\n",
            "           4       0.50      0.59      0.54       208\n",
            "           5       0.00      0.00      0.00        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.52       480\n",
            "   macro avg       0.20      0.26      0.23       480\n",
            "weighted avg       0.42      0.52      0.47       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "### Classification Report\n",
        "print(classification_report(y_test, y_pred_test_ada))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ5a7GEixuSV"
      },
      "source": [
        "**# Gradient Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quV2HgdPxp1_"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruJSGBHxyKTK"
      },
      "outputs": [],
      "source": [
        "GB= GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97lA_vJQyaN0",
        "outputId": "8d8c9374-638c-40ef-b014-02d68d58a6f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "GB_mod= GB.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODKwR2K2yib5",
        "outputId": "b4c998c7-ab2c-4523-bc93-f0c7380178d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 4, 5, ..., 4, 3, 4])"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' Predicting '''\n",
        "y_train_GB= GB_mod.predict(X_train)\n",
        "y_train_GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6KQqOTyywaq",
        "outputId": "48df3c26-0e37-4835-916b-9d5f7ea748e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 3, 4, 3, 5, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3,\n",
              "       4, 3, 3, 5, 4, 3, 4, 4, 3, 3, 4, 4, 5, 6, 4, 4, 3, 4, 3, 3, 3, 5,\n",
              "       3, 4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 4,\n",
              "       3, 4, 3, 4, 3, 3, 4, 3, 4, 3, 4, 5, 4, 4, 3, 4, 4, 3, 3, 4, 4, 3,\n",
              "       3, 4, 4, 3, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 3, 3, 4, 4, 3, 5, 3,\n",
              "       3, 3, 4, 4, 4, 3, 4, 3, 2, 3, 3, 3, 5, 3, 3, 4, 3, 3, 4, 3, 5, 2,\n",
              "       4, 4, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 2, 4, 3, 4, 2, 4, 4, 3,\n",
              "       4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 4,\n",
              "       3, 4, 4, 3, 4, 3, 1, 3, 4, 4, 3, 5, 3, 3, 4, 2, 4, 3, 3, 5, 3, 3,\n",
              "       4, 3, 4, 3, 3, 3, 4, 3, 4, 3, 5, 3, 3, 3, 3, 5, 3, 4, 3, 4, 3, 4,\n",
              "       4, 4, 3, 3, 5, 4, 3, 3, 3, 3, 3, 4, 5, 4, 4, 3, 4, 4, 4, 3, 4, 3,\n",
              "       4, 4, 3, 5, 3, 3, 6, 4, 3, 4, 3, 3, 4, 4, 4, 4, 3, 4, 3, 3, 3, 3,\n",
              "       3, 4, 3, 4, 4, 3, 5, 4, 3, 4, 3, 3, 3, 3, 3, 4, 4, 3, 4, 3, 3, 3,\n",
              "       3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 4, 4, 3, 4, 3, 4, 4, 3, 3, 4,\n",
              "       4, 4, 4, 5, 3, 3, 3, 3, 4, 4, 3, 4, 4, 4, 5, 4, 4, 3, 3, 4, 3, 3,\n",
              "       3, 3, 4, 4, 5, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 4,\n",
              "       3, 3, 3, 4, 3, 3, 3, 4, 5, 4, 3, 3, 3, 4, 5, 3, 5, 4, 3, 3, 4, 3,\n",
              "       3, 5, 5, 2, 4, 3, 6, 5, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 3, 5, 5,\n",
              "       4, 5, 4, 4, 4, 4, 5, 3, 4, 3, 4, 4, 3, 6, 3, 3, 4, 3, 4, 3, 3, 4,\n",
              "       4, 3, 4, 4, 3, 3, 3, 4, 4, 1, 4, 3, 3, 3, 4, 3, 3, 5, 4, 4, 3, 3,\n",
              "       3, 5, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 3, 4, 3, 3, 3, 3, 4, 4,\n",
              "       4, 3, 3, 4, 3, 4, 5, 3, 4, 3, 4, 4, 5, 3, 4, 4, 3, 3])"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' Predicting '''\n",
        "y_test_GB= GB_mod.predict(X_test)\n",
        "y_test_GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y_X4qpHzBrN",
        "outputId": "2b605926-8c86-45ff-9de9-231230409867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(round(accuracy_score(y_train, y_train_GB), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZmUdA0vzuO4",
        "outputId": "f8bca823-746a-4404-8ed4-f2dc6ca80280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.62\n"
          ]
        }
      ],
      "source": [
        "print(round(accuracy_score(y_test, y_test_GB), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjzSIeltz9KP"
      },
      "outputs": [],
      "source": [
        "### Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEFw3bP70Fep",
        "outputId": "2e51ffed-fb8e-495d-8028-0282927dee65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   1   3   0   0   0]\n",
            " [  0   1  12   5   0   0]\n",
            " [  2   3 146  25   2   1]\n",
            " [  0   1  71 127   9   0]\n",
            " [  0   0   3  35  26   3]\n",
            " [  0   0   0   4   0   0]]\n"
          ]
        }
      ],
      "source": [
        "confusion_matrix = confusion_matrix(y_test, y_test_GB)\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u60XOw_P0Neb",
        "outputId": "b60aee19-0742-432b-9b8c-6544cc3b23fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.17      0.06      0.08        18\n",
            "           3       0.62      0.82      0.71       179\n",
            "           4       0.65      0.61      0.63       208\n",
            "           5       0.70      0.39      0.50        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.62       480\n",
            "   macro avg       0.36      0.31      0.32       480\n",
            "weighted avg       0.62      0.62      0.61       480\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Classification Report\n",
        "print(classification_report(y_test, y_test_GB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6guYIft08I_"
      },
      "source": [
        "**#Know your Nearest Neighbors(KNN)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzjXkp3f0WnZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KLJzMNm1ZQo",
        "outputId": "61996ac4-7526-4c2f-9251-8c2fb3accac9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ],
      "source": [
        "knn= KNeighborsClassifier(n_neighbors = 5, algorithm= 'auto').fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKkiDqxO17Tl",
        "outputId": "3f74bf0b-dc36-46d0-b252-d8222e9d7725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3 3 4 3 4 4 3 4 3 3 3 3 4 3 4 4 5 3 5 4 3 3 3 3 3 4 4 4 3 4 3 3 4 3 5 4 4\n",
            " 3 3 4 3 3 3 4 3 4 3 3 4 3 3 4 6 3 3 3 4 3 3 4 3 3 3 4 5 3 3 3 3 4 3 3 3 3\n",
            " 4 3 4 2 3 4 3 5 4 4 4 4 3 3 3 4 4 3 5 3 4 4 4 3 3 4 4 3 4 3 4 4 4 4 4 4 3\n",
            " 4 3 4 4 3 4 3 2 3 3 4 4 3 3 4 3 3 3 3 4 3 4 3 4 4 4 3 3 3 4 3 5 3 3 5 2 4\n",
            " 3 5 4 4 4 3 4 3 3 3 3 3 4 4 4 3 3 3 3 4 5 3 3 3 3 3 4 4 3 4 3 3 3 4 3 3 4\n",
            " 4 3 4 3 2 3 3 4 3 4 5 4 4 4 4 3 3 3 3 3 3 4 4 4 3 3 3 3 5 4 4 4 3 3 3 4 4\n",
            " 3 4 4 5 3 3 4 3 3 4 4 3 5 3 3 3 4 4 4 4 3 3 4 4 3 3 3 4 3 4 3 3 4 3 3 3 3\n",
            " 3 3 4 4 3 4 5 4 3 4 4 3 3 4 3 4 4 3 3 3 5 4 3 3 3 3 4 3 3 4 3 3 4 3 3 3 3\n",
            " 3 4 3 4 4 4 4 3 3 3 3 3 5 3 3 4 3 4 3 3 3 3 3 4 3 4 5 4 4 3 4 3 3 3 4 3 4\n",
            " 3 4 4 4 3 3 3 4 3 3 3 3 3 4 4 4 4 3 4 3 3 3 3 3 3 3 3 5 4 3 3 3 4 4 3 4 3\n",
            " 4 4 3 4 3 4 5 3 4 4 4 4 4 4 4 4 3 5 4 3 3 3 3 3 5 4 4 4 5 4 4 4 4 3 3 3 3\n",
            " 4 3 3 3 3 3 3 4 3 4 3 3 3 4 3 4 3 3 3 3 3 3 3 4 3 4 3 3 5 4 4 4 4 3 5 3 3\n",
            " 3 3 3 3 3 3 3 3 3 4 3 3 4 3 3 3 4 4 4 4 3 4 3 3 4 3 3 3 3 4 5 4 4 3 3 4]\n"
          ]
        }
      ],
      "source": [
        "#Applying on Test data for prediction\n",
        "y_pred_KNN = knn.predict(X_test)\n",
        "print(y_pred_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-uZ1Z-N2P2E",
        "outputId": "b0066b07-0457-4c79-d27a-dff4d1cda8d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.46458333333333335"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prediction Score\n",
        "knn.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfz6sTD625F4",
        "outputId": "d95ed3af-0146-4fe2-8d9a-28ecfc564eab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.46458333333333335"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Accuracy Score\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JBgMCQe3COj",
        "outputId": "f4ae8710-b4b4-46d5-b6dd-62c04446bf79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   3,   1,   0,   0],\n",
              "       [  0,   0,  12,   6,   0,   0],\n",
              "       [  0,   2, 122,  55,   0,   0],\n",
              "       [  0,   1, 110,  87,  10,   0],\n",
              "       [  0,   1,  16,  35,  14,   1],\n",
              "       [  0,   0,   1,   1,   2,   0]])"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "knn_predictions = knn.predict(X_test)\n",
        "cm = confusion_matrix(y_test, knn_predictions)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDZHzzZ93JCm",
        "outputId": "fbd52664-8134-451d-c6ad-d71bf3e1f4b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.46      0.68      0.55       179\n",
            "           4       0.47      0.42      0.44       208\n",
            "           5       0.54      0.21      0.30        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.46       480\n",
            "   macro avg       0.25      0.22      0.22       480\n",
            "weighted avg       0.45      0.46      0.44       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "### Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, knn_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaRm-tuj4im9"
      },
      "source": [
        "**# SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcXpqK0A3L8t"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZM1NgUt4gsE",
        "outputId": "97844040-1e32-4350-9a17-66fdcc86994a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "svm_model= svm.SVC(kernel='linear', C=1, gamma='auto', probability= True).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N093ie054oA4"
      },
      "outputs": [],
      "source": [
        "y_pred_SVM = svm_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-c5Azmy4xsz",
        "outputId": "c50599a2-e498-45e9-c16c-c74e7ff50d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5354166666666667\n"
          ]
        }
      ],
      "source": [
        "# model accuracy for X_test \n",
        "accuracy = svm_model.score(X_test, y_test)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWLSsjCT414S",
        "outputId": "84623911-5e3e-4735-f339-9af193cd7f58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   4,   0,   0,   0],\n",
              "       [  0,   0,  16,   2,   0,   0],\n",
              "       [  0,   0, 146,  33,   0,   0],\n",
              "       [  0,   0,  97, 111,   0,   0],\n",
              "       [  0,   0,   2,  65,   0,   0],\n",
              "       [  0,   0,   0,   4,   0,   0]])"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred_SVM)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ROQiPL434H",
        "outputId": "0669cd4a-62b3-4b60-a556-1a5e572309a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.55      0.82      0.66       179\n",
            "           4       0.52      0.53      0.52       208\n",
            "           5       0.00      0.00      0.00        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.54       480\n",
            "   macro avg       0.18      0.22      0.20       480\n",
            "weighted avg       0.43      0.54      0.47       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "### Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_SVM))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_eEXMdG5IBv"
      },
      "source": [
        "**# Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGdEKujl47K7",
        "outputId": "721c59a2-d505-4618-c8b3-1a5a37615636"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r0nethj5Ai_"
      },
      "outputs": [],
      "source": [
        "y_pred_NB = gnb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PNjvuSK5SVA",
        "outputId": "505473bd-a91d-45aa-d4f8-db874f9e0044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.53125\n"
          ]
        }
      ],
      "source": [
        "# accuracy on X_test\n",
        "accuracy = gnb.score(X_test, y_test)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgKzoR2o5USo",
        "outputId": "0ae8efc4-da7d-4339-e57f-f86ffc90be84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   2,   2,   0,   0,   0],\n",
              "       [  0,   6,   8,   4,   0,   0],\n",
              "       [  0,   7, 139,  29,   4,   0],\n",
              "       [  0,   4, 101,  74,  28,   1],\n",
              "       [  0,   0,   3,  26,  36,   2],\n",
              "       [  0,   0,   0,   2,   2,   0]])"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_NB)\n",
        "cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFYpH4Ef5a8t",
        "outputId": "183b4016-9af3-444a-8dc0-17d947018475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.32      0.33      0.32        18\n",
            "           3       0.55      0.78      0.64       179\n",
            "           4       0.55      0.36      0.43       208\n",
            "           5       0.51      0.54      0.53        67\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.53       480\n",
            "   macro avg       0.32      0.33      0.32       480\n",
            "weighted avg       0.53      0.53      0.51       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "### Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_NB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siVbcgt75gsE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Red Wine Quality Model Building",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}